{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a11a4d4a",
   "metadata": {},
   "source": [
    "# Neural Network w/ backpropagation in Python from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432a4860",
   "metadata": {},
   "source": [
    "Lecture: https://www.youtube.com/watch?v=59Hbtz7XgjM\n",
    "Post: https://cs231n.github.io/optimization-2/\n",
    "Post: https://mattmazur.com/2015/03/17/a-step-by-step-backpropagation-example/\n",
    "Video: https://www.youtube.com/watch?v=4shguqlkTDM\n",
    "Code Inspiration: https://github.com/yacineMahdid/artificial-intelligence-and-machine-learning/blob/master/deep-learning-from-scratch-python/multi_layer_perceptron.ipynb (different data, try out different activations - sigmoid, ReLu, tanh)\n",
    "Code Inspiration 2: https://machinelearningmastery.com/implement-backpropagation-algorithm-scratch-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aafcb12d",
   "metadata": {},
   "source": [
    "### Functional Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "60059532",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from csv import reader\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee035d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = [[2.7810836,2.550537003, 0],\n",
    "           [1.465489372,2.362125076, 0],\n",
    "           [3.396561688,4.400293529, 0],\n",
    "           [1.38807019,1.850220317, 0],\n",
    "           [3.06407232,3.005305973, 0],\n",
    "           [7.627531214,2.759262235, 1],\n",
    "           [5.332441248,2.088626775, 1],\n",
    "           [6.922596716,1.77106367, 1],\n",
    "           [8.675418651,-0.242068655, 1],\n",
    "           [7.673756466,3.508563011, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5532f241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HIDDEN LAYER 1\n",
      "[{'params': [0.3487237855044789, 0.7648486226743969, 0.6608580080242392]}]\n",
      " \n",
      "OUTPUT LAYER\n",
      "[{'params': [0.7922861004551691, 0.9822940165221843]}, {'params': [0.8784281732681254, 0.648025418417123]}]\n"
     ]
    }
   ],
   "source": [
    "# 1. Initialize network with weights\n",
    "\n",
    "n_hidden = 1 # number of hidden layers\n",
    "n_inputs = len(train[0][:-1]) # number of features\n",
    "n_hidden_neurons = [1, 1] # number of neurons in hidden layer\n",
    "n_outputs = 2 # number of possible outputs to be predicted\n",
    "\n",
    "def init_network(n_inputs, n_hidden, n_hidden_neurons, n_outputs):\n",
    "\n",
    "    network = []\n",
    "    \n",
    "    # number of parameters = 1 per input (features in original data) + bias = n_inputs + 1\n",
    "    # number of neurons in layer = n_hidden_neurons[i]\n",
    "    i = 0\n",
    "    for n in range(n_hidden):\n",
    "        if i == 0:\n",
    "            hidden_layer = [{'params': [np.random.rand() for n in range(n_inputs + 1)]} for n in range(n_hidden_neurons[i])]\n",
    "        else:\n",
    "            hidden_layer = [{'params': [np.random.rand() for n in range(n_hidden_neurons[i-1] + 1)]} for n in range(n_hidden_neurons[i])]\n",
    "        network.append(hidden_layer)\n",
    "        i += 1\n",
    "        \n",
    "    # number of parameters = 1 per input (neurons in previous hidden layer) + bias = n_hidden + 1\n",
    "    # number of neurons in layer = n_outputs\n",
    "    output_layer = [{'params': [np.random.rand() for n in range(n_hidden_neurons[i-1] + 1)]} for n in range(n_outputs)]\n",
    "    network.append(output_layer)\n",
    "    \n",
    "    return network\n",
    "\n",
    "def print_layers(network):\n",
    "    i = 0\n",
    "    for layer in network:\n",
    "        if i < n_hidden:\n",
    "            print(f'HIDDEN LAYER {i+1}')\n",
    "            print(layer)\n",
    "            print(' ')\n",
    "        if i == n_hidden:\n",
    "            print('OUTPUT LAYER')\n",
    "            print(layer)\n",
    "        i += 1\n",
    "        \n",
    "network = init_network(n_inputs, n_hidden, n_hidden_neurons, n_outputs)\n",
    "\n",
    "print_layers(network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5762d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activation functions\n",
    "def sigmoid(output):\n",
    "    return 1.0 / (1.0 + np.exp(-output))\n",
    "\n",
    "def ReLu(output):\n",
    "    return max(0, output)\n",
    "\n",
    "def tanh(output):\n",
    "    return (np.exp(output)-np.exp(-output))/(np.exp(output)+np.exp(-output))\n",
    "\n",
    "activation_functions = ('sigmoid', 'ReLu', 'tanh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "303d0af2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8523464088490081, 0.817971577265889]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. Forward propagate\n",
    "\n",
    "# Calculates the output of a single neuron -> (weights * inputs) + bias\n",
    "def calc_neuron_output(params, inputs):\n",
    "    bias = params[-1]\n",
    "    output = bias\n",
    "    for i in range(len(params) - 1): # for every weight\n",
    "        output += params[i] * inputs[i]\n",
    "    return output\n",
    "\n",
    "def forward_propagate(network, inputs):\n",
    "    \n",
    "    for layer in network:\n",
    "        \n",
    "        # this list will store the activated output of each neuron to be the input of the next layer\n",
    "        # (in case the current layer is a hidden layer). Otherwise, this list will represent the outputs of the model\n",
    "        next_inputs = []\n",
    "        \n",
    "        for neuron in layer:\n",
    "            neuron_out = calc_neuron_output(neuron['params'], inputs) # linear output of neuron\n",
    "            neuron['output_activated'] = sigmoid(neuron_out) # sigmoid activation of linear output\n",
    "            next_inputs.append(neuron['output_activated'])\n",
    "            \n",
    "        inputs = next_inputs\n",
    "\n",
    "    return inputs # outputs of output layer\n",
    "\n",
    "forward_propagate(network, train[0][:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e095d180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Derivatives of activation functions\n",
    "def d_sigmoid(s):\n",
    "    return s*(1-s)\n",
    "\n",
    "def d_ReLu(r):\n",
    "    return 1 if r > 0 else 0\n",
    "\n",
    "def d_tanh(t):\n",
    "    return 1-t**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c81b581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HIDDEN LAYER 1\n",
      "[{'params': [0.3487237855044789, 0.7648486226743969, 0.6608580080242392], 'output_activated': 0.9729188489380506}]\n",
      " \n",
      "OUTPUT LAYER\n",
      "[{'params': [0.7922861004551691, 0.9822940165221843], 'output_activated': 0.8523464088490081}, {'params': [0.8784281732681254, 0.648025418417123], 'output_activated': 0.817971577265889}]\n"
     ]
    }
   ],
   "source": [
    "print_layers(network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e83fd4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Back propagate error\n",
    "\n",
    "# delta (error) for neuron in output layer = (y_pred-y_expected) * d_actv\n",
    "# delta (error) for neuron in hidden layers = sum(all connected weights from top layer * corresponding delta)\n",
    "\n",
    "# i is the ith layer of the network we are iterating through\n",
    "# expected_output are the expected outputs of the network (neurons in the output layer)\n",
    "##([1,0] for 0 , [0,1] for 1) (answer corresponds to the index where 1 is)\n",
    "\n",
    "def backpropagate(network, i, expected_output):\n",
    "    \n",
    "    # Base case -- backpropagation starts in output layer\n",
    "    if i == n_hidden:\n",
    "\n",
    "        for n in range(len(network[i])): # loop through each neuron in the layer i of the network (output layer)\n",
    "            neuron = network[i][n] # current neuron\n",
    "            error = neuron['output_activated'] - expected_output[n] # error for output in neuron n of output layer\n",
    "            neuron['delta'] = error * d_sigmoid(neuron['output_activated'])\n",
    "        return\n",
    "    # End of base case\n",
    "\n",
    "    errors = backpropagate(network, i + 1, expected_output)\n",
    "    \n",
    "    for n in range(len(network[i])): # loop through each neuron in the layer i of the network (hidden layer)\n",
    "        neuron = network[i][n] # current neuron\n",
    "        error = 0.0\n",
    "        for top_neuron in network[i+1]: # for each neuron in layer above\n",
    "            # (weights of top layer that the neuron output was multiplied by) * (corresponding delta)\n",
    "            error += top_neuron['params'][n] * top_neuron['delta']\n",
    "        neuron['delta'] = error * d_sigmoid(neuron['output_activated'])\n",
    "        \n",
    "    return\n",
    "            \n",
    "backpropagate(network, 0, [1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6417c4ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HIDDEN LAYER 1\n",
      "[{'params': [0.3487237855044789, 0.7648486226743969, 0.6608580080242392], 'output_activated': 0.9729188489380506, 'delta': 0.002430899771229981}]\n",
      " \n",
      "OUTPUT LAYER\n",
      "[{'params': [0.7922861004551691, 0.9822940165221843], 'output_activated': 0.8523464088490081, 'delta': -0.018582500960042773}, {'params': [0.8784281732681254, 0.648025418417123], 'output_activated': 0.817971577265889, 'delta': 0.1217911222330187}]\n"
     ]
    }
   ],
   "source": [
    "print_layers(network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9bbbab97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Train network\n",
    "\n",
    "def update_weights(network, row, lr):\n",
    "    for i in range(len(network)): # for every layer in the network\n",
    "        inputs = row[:-1] # take training inputs\n",
    "        if i != 0: # for all layers except the first\n",
    "            inputs = [neuron['output_activated'] for neuron in network[i-1]] # inputs are the output of the previous layer\n",
    "        for neuron in network[i]: # for every neuron in the layer\n",
    "            for j in range(len(inputs)): # for every input to the layer (every weight in the neuron)\n",
    "                neuron['params'][j] -= lr * neuron['delta'] * inputs[j] # weight update\n",
    "            neuron['params'][-1] -= lr * neuron['delta'] # bias update\n",
    "\n",
    "def train_network(network, training_data, lr, n_epochs):\n",
    "    \n",
    "    for n_epoch in range(n_epochs):\n",
    "        sse = 0.0\n",
    "        \n",
    "        for row in training_data:\n",
    "            output = forward_propagate(network, row)\n",
    "            expected = [0 for i in range(len(output))] # initialize to an array of 0s of same size as outputs\n",
    "            expected[row[-1]] = 1 # if actual output is 1, expected is [0,1], if 0 it is [1,0]\n",
    "            sse += sum([(expected[i]-output[i])**2 for i in range(len(expected))])\n",
    "            backpropagate(network, 0, expected)\n",
    "            update_weights(network, row, lr)\n",
    "        \n",
    "        if n_epoch % 10 == 0:\n",
    "            print('>epoch=%d, error=%.3f' % (n_epoch, sse)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44af0b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">epoch=0, error=5.480\n",
      ">epoch=10, error=5.124\n",
      ">epoch=20, error=5.117\n",
      ">epoch=30, error=5.116\n",
      ">epoch=40, error=5.114\n",
      ">epoch=50, error=5.113\n",
      ">epoch=60, error=5.111\n",
      ">epoch=70, error=5.109\n",
      ">epoch=80, error=5.106\n",
      ">epoch=90, error=5.101\n",
      ">epoch=100, error=5.094\n",
      ">epoch=110, error=5.081\n",
      ">epoch=120, error=5.051\n",
      ">epoch=130, error=4.935\n",
      ">epoch=140, error=4.308\n",
      ">epoch=150, error=3.195\n",
      ">epoch=160, error=2.245\n",
      ">epoch=170, error=1.616\n",
      ">epoch=180, error=1.215\n",
      ">epoch=190, error=0.953\n",
      ">epoch=200, error=0.774\n",
      ">epoch=210, error=0.645\n",
      ">epoch=220, error=0.550\n",
      ">epoch=230, error=0.478\n",
      ">epoch=240, error=0.421\n",
      ">epoch=250, error=0.375\n",
      ">epoch=260, error=0.337\n",
      ">epoch=270, error=0.306\n",
      ">epoch=280, error=0.280\n",
      ">epoch=290, error=0.258\n",
      ">epoch=300, error=0.239\n",
      ">epoch=310, error=0.222\n",
      ">epoch=320, error=0.207\n",
      ">epoch=330, error=0.194\n",
      ">epoch=340, error=0.183\n",
      ">epoch=350, error=0.173\n",
      ">epoch=360, error=0.163\n",
      ">epoch=370, error=0.155\n",
      ">epoch=380, error=0.148\n",
      ">epoch=390, error=0.141\n",
      ">epoch=400, error=0.134\n",
      ">epoch=410, error=0.129\n",
      ">epoch=420, error=0.123\n",
      ">epoch=430, error=0.118\n",
      ">epoch=440, error=0.114\n",
      ">epoch=450, error=0.110\n",
      ">epoch=460, error=0.106\n",
      ">epoch=470, error=0.102\n",
      ">epoch=480, error=0.099\n",
      ">epoch=490, error=0.095\n"
     ]
    }
   ],
   "source": [
    "def backprop(training_data, lr, n_epochs, n_inputs, n_hidden, n_hidden_neurons, n_outputs):\n",
    "    model = init_network(n_inputs, n_hidden, n_hidden_neurons, n_outputs)\n",
    "    train_network(model, training_data, lr, n_epochs)\n",
    "    \n",
    "    return model\n",
    "    \n",
    "lr = 0.2\n",
    "training_data = train\n",
    "n_epochs = 500\n",
    "\n",
    "model = backprop(training_data, lr, n_epochs, n_inputs, n_hidden, n_hidden_neurons, n_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "897c88a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### 5. Predict\n",
    "def predict(model, train):\n",
    "    \n",
    "    preds = [] # stores the predictions of all data points of the training data\n",
    "    \n",
    "    for row in training_data:\n",
    "        label = row[-1]\n",
    "        features = row[:-1]\n",
    "        outputs = forward_propagate(model, features)\n",
    "        pred = outputs.index(max(outputs))\n",
    "        preds.append(pred)\n",
    "    \n",
    "    return preds\n",
    "\n",
    "predict(model, train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ff529cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a csv file\n",
    "def load_csv(filename):\n",
    "    dataset = list()\n",
    "    with open(filename, 'r') as file:\n",
    "        csv_reader = reader(file)\n",
    "        for row in csv_reader:\n",
    "            if not row:\n",
    "                continue\n",
    "            dataset.append(row)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "95689dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">epoch=0, error=114.003\n",
      ">epoch=10, error=50.099\n",
      ">epoch=20, error=49.772\n",
      ">epoch=30, error=49.148\n",
      ">epoch=40, error=48.828\n",
      ">epoch=50, error=48.565\n",
      ">epoch=60, error=48.220\n",
      ">epoch=70, error=47.708\n",
      ">epoch=80, error=46.869\n",
      ">epoch=90, error=45.372\n",
      ">epoch=100, error=42.560\n",
      ">epoch=110, error=37.907\n",
      ">epoch=120, error=33.022\n",
      ">epoch=130, error=29.767\n",
      ">epoch=140, error=27.635\n",
      ">epoch=150, error=26.198\n",
      ">epoch=160, error=25.205\n",
      ">epoch=170, error=24.485\n",
      ">epoch=180, error=23.937\n",
      ">epoch=190, error=23.500\n",
      ">epoch=200, error=23.140\n",
      ">epoch=210, error=22.838\n",
      ">epoch=220, error=22.580\n",
      ">epoch=230, error=22.358\n",
      ">epoch=240, error=22.164\n",
      ">epoch=250, error=21.994\n",
      ">epoch=260, error=21.844\n",
      ">epoch=270, error=21.711\n",
      ">epoch=280, error=21.593\n",
      ">epoch=290, error=21.486\n",
      ">epoch=300, error=21.391\n",
      ">epoch=310, error=21.305\n",
      ">epoch=320, error=21.227\n",
      ">epoch=330, error=21.156\n",
      ">epoch=340, error=21.091\n",
      ">epoch=350, error=21.032\n",
      ">epoch=360, error=20.978\n",
      ">epoch=370, error=20.929\n",
      ">epoch=380, error=20.883\n",
      ">epoch=390, error=20.841\n",
      ">epoch=400, error=20.802\n",
      ">epoch=410, error=20.766\n",
      ">epoch=420, error=20.733\n",
      ">epoch=430, error=20.701\n",
      ">epoch=440, error=20.672\n",
      ">epoch=450, error=20.645\n",
      ">epoch=460, error=20.620\n",
      ">epoch=470, error=20.596\n",
      ">epoch=480, error=20.574\n",
      ">epoch=490, error=20.553\n"
     ]
    }
   ],
   "source": [
    "# 6. Predict on fraud detection dataset - https://www.kaggle.com/datasets/whenamancodes/fraud-detection?resource=download\n",
    "\n",
    "ccard_data = load_csv('creditcard.csv')\n",
    "ccard_data_mod = []\n",
    "i = 0\n",
    "for row in ccard_data: # take only first 2 features and output, convert from string to float/integer\n",
    "    if i != 0:\n",
    "        new_row = row[1:3]\n",
    "        for j in range(len(new_row)):\n",
    "            new_row[j] = float(new_row[j])\n",
    "        new_row.append(int(row[30]))\n",
    "\n",
    "        ccard_data_mod.append(new_row)\n",
    "    i += 1\n",
    "\n",
    "traincc = ccard_data_mod[:8000]\n",
    "testcc = ccard_data_mod[8000:10000]\n",
    "\n",
    "lr = 0.1\n",
    "training_data = traincc\n",
    "n_epochscc = 500\n",
    "\n",
    "n_hiddencc = 1 # number of hidden layers\n",
    "n_inputscc = len(traincc[0][:-1]) # number of features\n",
    "n_hidden_neuronscc = [1,1] # number of neurons in hidden layer\n",
    "n_outputscc = 2 # number of possible outputs to be predicted\n",
    "\n",
    "modelcc = backprop(traincc, lr, n_epochscc, n_inputscc, n_hiddencc, n_hidden_neuronscc, n_outputscc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "5e285659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "class ConfusionMatrix:\n",
    "    \n",
    "    def __init__(self, modelcm, data):\n",
    "        self.model = modelcm\n",
    "        self.data = data\n",
    "        self.conf_matrix = None\n",
    "        \n",
    "        # METRICS\n",
    "        self.accuracy = 0.0\n",
    "        self.precision = 0.0\n",
    "        self.recall = 0.0\n",
    "        self.fprate = 0.0\n",
    "        self.fnrate = 0.0\n",
    "        \n",
    "    def predict(self):\n",
    "    \n",
    "        preds = [] # stores the predictions of all data points of the training data\n",
    "\n",
    "        for row in self.data:\n",
    "            label = row[-1]\n",
    "            features = row[:-1]\n",
    "            outputs = forward_propagate(self.model, features)\n",
    "            pred = outputs.index(max(outputs))\n",
    "            preds.append(pred)\n",
    "\n",
    "        return preds\n",
    "    \n",
    "    def print_matrix(self):\n",
    "        print(self.conf_matrix)\n",
    "        print(' ')\n",
    "        \n",
    "    def print_metrics(self):\n",
    "        # Accuracy (what fraction does it get right) = (# TP + # TN) / Total\n",
    "        self.accuracy = (self.conf_matrix['TPs'] + self.conf_matrix['TNs']) / sum(self.conf_matrix.values())\n",
    "        print('ACCURACY: ', round(self.accuracy, 3))\n",
    "        print(' ')\n",
    "        \n",
    "        # Precision (when it says 1, how often is it right) = # TP / (# TP + # FP)\n",
    "        self.precision = self.conf_matrix['TPs'] / (self.conf_matrix['TPs'] + self.conf_matrix['FPs'])\n",
    "        print('PRECISION: ', round(self.precision, 3))\n",
    "        print(' ')\n",
    "        \n",
    "        # Recall (what fraction of 1s does it get right) = # TP / (# TP + # FN)\n",
    "        self.recall = self.conf_matrix['TPs'] / (self.conf_matrix['TPs'] + self.conf_matrix['FNs'])\n",
    "        print('RECALL: ', round(self.recall, 3))\n",
    "        print(' ')\n",
    "        \n",
    "        # False positive rate (what fraction of 0s are called 1s) = # FP / (# FP + # TN)\n",
    "        self.fprate = self.conf_matrix['FPs'] / (self.conf_matrix['FPs'] + self.conf_matrix['TNs'])\n",
    "        print('FALSE POSITIVE RATE: ', round(self.fprate, 3))\n",
    "        print(' ')\n",
    "        \n",
    "        # False negative rate (what fraction of 1s are called 0s) = # FN / (# TP + # FN)\n",
    "        self.fnrate = self.conf_matrix['FNs'] / (self.conf_matrix['TPs'] + self.conf_matrix['FNs'])\n",
    "        print('FALSE NEGATIVE RATE: ', round(self.fnrate, 3))\n",
    "    \n",
    "    \n",
    "    def plot_matrix(self):\n",
    "        matrix_arr = [[self.conf_matrix['TNs'], self.conf_matrix['FPs']], [self.conf_matrix['FNs'], self.conf_matrix['TPs']]]\n",
    "        plt.imshow(matrix_arr, cmap = 'coolwarm', alpha = 0.5)\n",
    "        plt.xticks(np.arange(0, 2), ['0', '1'])\n",
    "        plt.yticks(np.arange(0, 2), ['0', '1'])\n",
    "        \n",
    "        plt.text(-0.1, 0, matrix_arr[0][0], fontsize = 14) # TNs\n",
    "        plt.text(0.95, 0, matrix_arr[0][1], fontsize = 14) # FPs\n",
    "        plt.text(-0.1, 1, matrix_arr[1][0], fontsize = 14) # FNs\n",
    "        plt.text(0.95, 1, matrix_arr[1][1], fontsize = 14) # TPs\n",
    "\n",
    "        plt.xlabel('Predictions', fontsize=18)\n",
    "        plt.ylabel('Actuals', fontsize=18)\n",
    "        plt.title('Confusion Matrix', fontsize=18)\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "    def fit(self):\n",
    "        self.conf_matrix = {'TPs': 0, 'TNs': 0, 'FPs': 0, 'FNs': 0}\n",
    "        \n",
    "        preds = self.predict()\n",
    "        \n",
    "        for i in range(len(preds)):\n",
    "            label = self.data[i][-1]\n",
    "            pred = preds[i]\n",
    "            if label == 1 and pred == 1: # truly predicted positive\n",
    "                self.conf_matrix['TPs'] += 1\n",
    "            elif label == 0 and pred == 1: # falsely predicted positive\n",
    "                self.conf_matrix['FPs'] += 1\n",
    "            elif label == 1 and pred == 0: # falsely predicted negative\n",
    "                self.conf_matrix['FNs'] += 1\n",
    "            elif label == 0 and pred == 0: # truly predicted negative\n",
    "                self.conf_matrix['TNs'] += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "5d8f92d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY:  0.996\n",
      " \n",
      "PRECISION:  0.625\n",
      " \n",
      "RECALL:  0.769\n",
      " \n",
      "FALSE POSITIVE RATE:  0.003\n",
      " \n",
      "FALSE NEGATIVE RATE:  0.231\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cc_cm = ConfusionMatrix(modelcc, testcc)\n",
    "cc_cm.fit()\n",
    "cc_cm.print_metrics()\n",
    "cc_cm.plot_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3751c38e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.2021911 , 0.86663459],\n",
       "       [0.26005507, 0.48487318]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 7. Predict on titanic dataset - https://www.kaggle.com/competitions/titanic/data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566f0a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "[[]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
