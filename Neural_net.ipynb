{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a11a4d4a",
   "metadata": {},
   "source": [
    "# Neural Network w/ backpropagation in Python from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432a4860",
   "metadata": {},
   "source": [
    "Lecture: https://www.youtube.com/watch?v=59Hbtz7XgjM\n",
    "Post: https://cs231n.github.io/optimization-2/\n",
    "Post: https://mattmazur.com/2015/03/17/a-step-by-step-backpropagation-example/\n",
    "Video: https://www.youtube.com/watch?v=4shguqlkTDM\n",
    "Code Inspiration: https://github.com/yacineMahdid/artificial-intelligence-and-machine-learning/blob/master/deep-learning-from-scratch-python/multi_layer_perceptron.ipynb (different data, try out different activations - sigmoid, ReLu, tanh)\n",
    "Code Inspiration 2: https://machinelearningmastery.com/implement-backpropagation-algorithm-scratch-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aafcb12d",
   "metadata": {},
   "source": [
    "### Functional Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "60059532",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from csv import reader\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee035d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = [[2.7810836,2.550537003, 0],\n",
    "           [1.465489372,2.362125076, 0],\n",
    "           [3.396561688,4.400293529, 0],\n",
    "           [1.38807019,1.850220317, 0],\n",
    "           [3.06407232,3.005305973, 0],\n",
    "           [7.627531214,2.759262235, 1],\n",
    "           [5.332441248,2.088626775, 1],\n",
    "           [6.922596716,1.77106367, 1],\n",
    "           [8.675418651,-0.242068655, 1],\n",
    "           [7.673756466,3.508563011, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5532f241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HIDDEN LAYER 1\n",
      "[{'params': [0.3487237855044789, 0.7648486226743969, 0.6608580080242392]}]\n",
      " \n",
      "OUTPUT LAYER\n",
      "[{'params': [0.7922861004551691, 0.9822940165221843]}, {'params': [0.8784281732681254, 0.648025418417123]}]\n"
     ]
    }
   ],
   "source": [
    "# 1. Initialize network with weights\n",
    "\n",
    "n_hidden = 1 # number of hidden layers\n",
    "n_inputs = len(train[0][:-1]) # number of features\n",
    "n_hidden_neurons = [1, 1] # number of neurons in hidden layer\n",
    "n_outputs = 2 # number of possible outputs to be predicted\n",
    "\n",
    "def init_network(n_inputs, n_hidden, n_hidden_neurons, n_outputs):\n",
    "\n",
    "    network = []\n",
    "    \n",
    "    # number of parameters = 1 per input (features in original data) + bias = n_inputs + 1\n",
    "    # number of neurons in layer = n_hidden_neurons[i]\n",
    "    i = 0\n",
    "    for n in range(n_hidden):\n",
    "        if i == 0:\n",
    "            hidden_layer = [{'params': [np.random.rand() for n in range(n_inputs + 1)]} for n in range(n_hidden_neurons[i])]\n",
    "        else:\n",
    "            hidden_layer = [{'params': [np.random.rand() for n in range(n_hidden_neurons[i-1] + 1)]} for n in range(n_hidden_neurons[i])]\n",
    "        network.append(hidden_layer)\n",
    "        i += 1\n",
    "        \n",
    "    # number of parameters = 1 per input (neurons in previous hidden layer) + bias = n_hidden + 1\n",
    "    # number of neurons in layer = n_outputs\n",
    "    output_layer = [{'params': [np.random.rand() for n in range(n_hidden_neurons[i-1] + 1)]} for n in range(n_outputs)]\n",
    "    network.append(output_layer)\n",
    "    \n",
    "    return network\n",
    "\n",
    "def print_layers(network):\n",
    "    i = 0\n",
    "    for layer in network:\n",
    "        if i < n_hidden:\n",
    "            print(f'HIDDEN LAYER {i+1}')\n",
    "            print(layer)\n",
    "            print(' ')\n",
    "        if i == n_hidden:\n",
    "            print('OUTPUT LAYER')\n",
    "            print(layer)\n",
    "        i += 1\n",
    "        \n",
    "network = init_network(n_inputs, n_hidden, n_hidden_neurons, n_outputs)\n",
    "\n",
    "print_layers(network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5762d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activation functions\n",
    "def sigmoid(output):\n",
    "    return 1.0 / (1.0 + np.exp(-output))\n",
    "\n",
    "def ReLu(output):\n",
    "    return max(0, output)\n",
    "\n",
    "def tanh(output):\n",
    "    return (np.exp(output)-np.exp(-output))/(np.exp(output)+np.exp(-output))\n",
    "\n",
    "activation_functions = ('sigmoid', 'ReLu', 'tanh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "303d0af2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8523464088490081, 0.817971577265889]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. Forward propagate\n",
    "\n",
    "# Calculates the output of a single neuron -> (weights * inputs) + bias\n",
    "def calc_neuron_output(params, inputs):\n",
    "    bias = params[-1]\n",
    "    output = bias\n",
    "    for i in range(len(params) - 1): # for every weight\n",
    "        output += params[i] * inputs[i]\n",
    "    return output\n",
    "\n",
    "def forward_propagate(network, inputs):\n",
    "    \n",
    "    for layer in network:\n",
    "        \n",
    "        # this list will store the activated output of each neuron to be the input of the next layer\n",
    "        # (in case the current layer is a hidden layer). Otherwise, this list will represent the outputs of the model\n",
    "        next_inputs = []\n",
    "        \n",
    "        for neuron in layer:\n",
    "            neuron_out = calc_neuron_output(neuron['params'], inputs) # linear output of neuron\n",
    "            neuron['output_activated'] = sigmoid(neuron_out) # sigmoid activation of linear output\n",
    "            next_inputs.append(neuron['output_activated'])\n",
    "            \n",
    "        inputs = next_inputs\n",
    "\n",
    "    return inputs # outputs of output layer\n",
    "\n",
    "forward_propagate(network, train[0][:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e095d180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Derivatives of activation functions\n",
    "def d_sigmoid(s):\n",
    "    return s*(1-s)\n",
    "\n",
    "def d_ReLu(r):\n",
    "    return 1 if r > 0 else 0\n",
    "\n",
    "def d_tanh(t):\n",
    "    return 1-t**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c81b581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HIDDEN LAYER 1\n",
      "[{'params': [0.3487237855044789, 0.7648486226743969, 0.6608580080242392], 'output_activated': 0.9729188489380506}]\n",
      " \n",
      "OUTPUT LAYER\n",
      "[{'params': [0.7922861004551691, 0.9822940165221843], 'output_activated': 0.8523464088490081}, {'params': [0.8784281732681254, 0.648025418417123], 'output_activated': 0.817971577265889}]\n"
     ]
    }
   ],
   "source": [
    "print_layers(network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e83fd4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Back propagate error\n",
    "\n",
    "# delta (error) for neuron in output layer = (y_pred-y_expected) * d_actv\n",
    "# delta (error) for neuron in hidden layers = sum(all connected weights from top layer * corresponding delta)\n",
    "\n",
    "# i is the ith layer of the network we are iterating through\n",
    "# expected_output are the expected outputs of the network (neurons in the output layer)\n",
    "##([1,0] for 0 , [0,1] for 1) (answer corresponds to the index where 1 is)\n",
    "\n",
    "def backpropagate(network, i, expected_output):\n",
    "    \n",
    "    # Base case -- backpropagation starts in output layer\n",
    "    if i == n_hidden:\n",
    "\n",
    "        for n in range(len(network[i])): # loop through each neuron in the layer i of the network (output layer)\n",
    "            neuron = network[i][n] # current neuron\n",
    "            error = neuron['output_activated'] - expected_output[n] # error for output in neuron n of output layer\n",
    "            neuron['delta'] = error * d_sigmoid(neuron['output_activated'])\n",
    "        return\n",
    "    # End of base case\n",
    "\n",
    "    errors = backpropagate(network, i + 1, expected_output)\n",
    "    \n",
    "    for n in range(len(network[i])): # loop through each neuron in the layer i of the network (hidden layer)\n",
    "        neuron = network[i][n] # current neuron\n",
    "        error = 0.0\n",
    "        for top_neuron in network[i+1]: # for each neuron in layer above\n",
    "            # (weights of top layer that the neuron output was multiplied by) * (corresponding delta)\n",
    "            error += top_neuron['params'][n] * top_neuron['delta']\n",
    "        neuron['delta'] = error * d_sigmoid(neuron['output_activated'])\n",
    "        \n",
    "    return\n",
    "            \n",
    "backpropagate(network, 0, [1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6417c4ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HIDDEN LAYER 1\n",
      "[{'params': [0.3487237855044789, 0.7648486226743969, 0.6608580080242392], 'output_activated': 0.9729188489380506, 'delta': 0.002430899771229981}]\n",
      " \n",
      "OUTPUT LAYER\n",
      "[{'params': [0.7922861004551691, 0.9822940165221843], 'output_activated': 0.8523464088490081, 'delta': -0.018582500960042773}, {'params': [0.8784281732681254, 0.648025418417123], 'output_activated': 0.817971577265889, 'delta': 0.1217911222330187}]\n"
     ]
    }
   ],
   "source": [
    "print_layers(network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9bbbab97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Train network\n",
    "\n",
    "def update_weights(network, row, lr):\n",
    "    for i in range(len(network)): # for every layer in the network\n",
    "        inputs = row[:-1] # take training inputs\n",
    "        if i != 0: # for all layers except the first\n",
    "            inputs = [neuron['output_activated'] for neuron in network[i-1]] # inputs are the output of the previous layer\n",
    "        for neuron in network[i]: # for every neuron in the layer\n",
    "            for j in range(len(inputs)): # for every input to the layer (every weight in the neuron)\n",
    "                neuron['params'][j] -= lr * neuron['delta'] * inputs[j] # weight update\n",
    "            neuron['params'][-1] -= lr * neuron['delta'] # bias update\n",
    "\n",
    "def train_network(network, training_data, lr, n_epochs):\n",
    "    \n",
    "    for n_epoch in range(n_epochs):\n",
    "        sse = 0.0\n",
    "        \n",
    "        for row in training_data:\n",
    "            output = forward_propagate(network, row)\n",
    "            expected = [0 for i in range(len(output))] # initialize to an array of 0s of same size as outputs\n",
    "            expected[row[-1]] = 1 # if actual output is 1, expected is [0,1], if 0 it is [1,0]\n",
    "            sse += sum([(expected[i]-output[i])**2 for i in range(len(expected))])\n",
    "            backpropagate(network, 0, expected)\n",
    "            update_weights(network, row, lr)\n",
    "        \n",
    "        if n_epoch % 10 == 0:\n",
    "            print('>epoch=%d, error=%.3f' % (n_epoch, sse)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44af0b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">epoch=0, error=5.480\n",
      ">epoch=10, error=5.124\n",
      ">epoch=20, error=5.117\n",
      ">epoch=30, error=5.116\n",
      ">epoch=40, error=5.114\n",
      ">epoch=50, error=5.113\n",
      ">epoch=60, error=5.111\n",
      ">epoch=70, error=5.109\n",
      ">epoch=80, error=5.106\n",
      ">epoch=90, error=5.101\n",
      ">epoch=100, error=5.094\n",
      ">epoch=110, error=5.081\n",
      ">epoch=120, error=5.051\n",
      ">epoch=130, error=4.935\n",
      ">epoch=140, error=4.308\n",
      ">epoch=150, error=3.195\n",
      ">epoch=160, error=2.245\n",
      ">epoch=170, error=1.616\n",
      ">epoch=180, error=1.215\n",
      ">epoch=190, error=0.953\n",
      ">epoch=200, error=0.774\n",
      ">epoch=210, error=0.645\n",
      ">epoch=220, error=0.550\n",
      ">epoch=230, error=0.478\n",
      ">epoch=240, error=0.421\n",
      ">epoch=250, error=0.375\n",
      ">epoch=260, error=0.337\n",
      ">epoch=270, error=0.306\n",
      ">epoch=280, error=0.280\n",
      ">epoch=290, error=0.258\n",
      ">epoch=300, error=0.239\n",
      ">epoch=310, error=0.222\n",
      ">epoch=320, error=0.207\n",
      ">epoch=330, error=0.194\n",
      ">epoch=340, error=0.183\n",
      ">epoch=350, error=0.173\n",
      ">epoch=360, error=0.163\n",
      ">epoch=370, error=0.155\n",
      ">epoch=380, error=0.148\n",
      ">epoch=390, error=0.141\n",
      ">epoch=400, error=0.134\n",
      ">epoch=410, error=0.129\n",
      ">epoch=420, error=0.123\n",
      ">epoch=430, error=0.118\n",
      ">epoch=440, error=0.114\n",
      ">epoch=450, error=0.110\n",
      ">epoch=460, error=0.106\n",
      ">epoch=470, error=0.102\n",
      ">epoch=480, error=0.099\n",
      ">epoch=490, error=0.095\n"
     ]
    }
   ],
   "source": [
    "def backprop(training_data, lr, n_epochs, n_inputs, n_hidden, n_hidden_neurons, n_outputs):\n",
    "    model = init_network(n_inputs, n_hidden, n_hidden_neurons, n_outputs)\n",
    "    train_network(model, training_data, lr, n_epochs)\n",
    "    \n",
    "    return model\n",
    "    \n",
    "lr = 0.2\n",
    "training_data = train\n",
    "n_epochs = 500\n",
    "\n",
    "model = backprop(training_data, lr, n_epochs, n_inputs, n_hidden, n_hidden_neurons, n_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "897c88a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### 5. Predict\n",
    "def predict(model, train):\n",
    "    \n",
    "    preds = [] # stores the predictions of all data points of the training data\n",
    "    \n",
    "    for row in training_data:\n",
    "        label = row[-1]\n",
    "        features = row[:-1]\n",
    "        outputs = forward_propagate(model, features)\n",
    "        pred = outputs.index(max(outputs))\n",
    "        preds.append(pred)\n",
    "    \n",
    "    return preds\n",
    "\n",
    "predict(model, train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ff529cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a csv file\n",
    "def load_csv(filename):\n",
    "    dataset = list()\n",
    "    with open(filename, 'r') as file:\n",
    "        csv_reader = reader(file)\n",
    "        for row in csv_reader:\n",
    "            if not row:\n",
    "                continue\n",
    "            dataset.append(row)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "95689dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">epoch=0, error=114.003\n",
      ">epoch=10, error=50.099\n",
      ">epoch=20, error=49.772\n",
      ">epoch=30, error=49.148\n",
      ">epoch=40, error=48.828\n",
      ">epoch=50, error=48.565\n",
      ">epoch=60, error=48.220\n",
      ">epoch=70, error=47.708\n",
      ">epoch=80, error=46.869\n",
      ">epoch=90, error=45.372\n",
      ">epoch=100, error=42.560\n",
      ">epoch=110, error=37.907\n",
      ">epoch=120, error=33.022\n",
      ">epoch=130, error=29.767\n",
      ">epoch=140, error=27.635\n",
      ">epoch=150, error=26.198\n",
      ">epoch=160, error=25.205\n",
      ">epoch=170, error=24.485\n",
      ">epoch=180, error=23.937\n",
      ">epoch=190, error=23.500\n",
      ">epoch=200, error=23.140\n",
      ">epoch=210, error=22.838\n",
      ">epoch=220, error=22.580\n",
      ">epoch=230, error=22.358\n",
      ">epoch=240, error=22.164\n",
      ">epoch=250, error=21.994\n",
      ">epoch=260, error=21.844\n",
      ">epoch=270, error=21.711\n",
      ">epoch=280, error=21.593\n",
      ">epoch=290, error=21.486\n",
      ">epoch=300, error=21.391\n",
      ">epoch=310, error=21.305\n",
      ">epoch=320, error=21.227\n",
      ">epoch=330, error=21.156\n",
      ">epoch=340, error=21.091\n",
      ">epoch=350, error=21.032\n",
      ">epoch=360, error=20.978\n",
      ">epoch=370, error=20.929\n",
      ">epoch=380, error=20.883\n",
      ">epoch=390, error=20.841\n",
      ">epoch=400, error=20.802\n",
      ">epoch=410, error=20.766\n",
      ">epoch=420, error=20.733\n",
      ">epoch=430, error=20.701\n",
      ">epoch=440, error=20.672\n",
      ">epoch=450, error=20.645\n",
      ">epoch=460, error=20.620\n",
      ">epoch=470, error=20.596\n",
      ">epoch=480, error=20.574\n",
      ">epoch=490, error=20.553\n"
     ]
    }
   ],
   "source": [
    "# 6. Predict on fraud detection dataset - https://www.kaggle.com/datasets/whenamancodes/fraud-detection?resource=download\n",
    "\n",
    "ccard_data = load_csv('creditcard.csv')\n",
    "ccard_data_mod = []\n",
    "i = 0\n",
    "for row in ccard_data: # take only first 2 features and output, convert from string to float/integer\n",
    "    if i != 0:\n",
    "        new_row = row[1:3]\n",
    "        for j in range(len(new_row)):\n",
    "            new_row[j] = float(new_row[j])\n",
    "        new_row.append(int(row[30]))\n",
    "\n",
    "        ccard_data_mod.append(new_row)\n",
    "    i += 1\n",
    "\n",
    "traincc = ccard_data_mod[:8000]\n",
    "testcc = ccard_data_mod[8000:10000]\n",
    "\n",
    "lr = 0.1\n",
    "training_data = traincc\n",
    "n_epochscc = 500\n",
    "\n",
    "n_hiddencc = 1 # number of hidden layers\n",
    "n_inputscc = len(traincc[0][:-1]) # number of features\n",
    "n_hidden_neuronscc = [1,1] # number of neurons in hidden layer\n",
    "n_outputscc = 2 # number of possible outputs to be predicted\n",
    "\n",
    "modelcc = backprop(traincc, lr, n_epochscc, n_inputscc, n_hiddencc, n_hidden_neuronscc, n_outputscc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "5e285659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "class ConfusionMatrix:\n",
    "    \n",
    "    def __init__(self, modelcm, data):\n",
    "        self.model = modelcm\n",
    "        self.data = data\n",
    "        self.conf_matrix = None\n",
    "        \n",
    "        # METRICS\n",
    "        self.accuracy = 0.0\n",
    "        self.precision = 0.0\n",
    "        self.recall = 0.0\n",
    "        self.fprate = 0.0\n",
    "        self.fnrate = 0.0\n",
    "        \n",
    "    def predict(self):\n",
    "    \n",
    "        preds = [] # stores the predictions of all data points of the training data\n",
    "\n",
    "        for row in self.data:\n",
    "            label = row[-1]\n",
    "            features = row[:-1]\n",
    "            outputs = forward_propagate(self.model, features)\n",
    "            pred = outputs.index(max(outputs))\n",
    "            preds.append(pred)\n",
    "\n",
    "        return preds\n",
    "    \n",
    "    def print_matrix(self):\n",
    "        print(self.conf_matrix)\n",
    "        print(' ')\n",
    "        \n",
    "    def print_metrics(self):\n",
    "        # Accuracy (what fraction does it get right) = (# TP + # TN) / Total\n",
    "        self.accuracy = (self.conf_matrix['TPs'] + self.conf_matrix['TNs']) / sum(self.conf_matrix.values())\n",
    "        print('ACCURACY: ', round(self.accuracy, 3))\n",
    "        print(' ')\n",
    "        \n",
    "        # Precision (when it says 1, how often is it right) = # TP / (# TP + # FP)\n",
    "        self.precision = self.conf_matrix['TPs'] / (self.conf_matrix['TPs'] + self.conf_matrix['FPs'])\n",
    "        print('PRECISION: ', round(self.precision, 3))\n",
    "        print(' ')\n",
    "        \n",
    "        # Recall (what fraction of 1s does it get right) = # TP / (# TP + # FN)\n",
    "        self.recall = self.conf_matrix['TPs'] / (self.conf_matrix['TPs'] + self.conf_matrix['FNs'])\n",
    "        print('RECALL: ', round(self.recall, 3))\n",
    "        print(' ')\n",
    "        \n",
    "        # False positive rate (what fraction of 0s are called 1s) = # FP / (# FP + # TN)\n",
    "        self.fprate = self.conf_matrix['FPs'] / (self.conf_matrix['FPs'] + self.conf_matrix['TNs'])\n",
    "        print('FALSE POSITIVE RATE: ', round(self.fprate, 3))\n",
    "        print(' ')\n",
    "        \n",
    "        # False negative rate (what fraction of 1s are called 0s) = # FN / (# TP + # FN)\n",
    "        self.fnrate = self.conf_matrix['FNs'] / (self.conf_matrix['TPs'] + self.conf_matrix['FNs'])\n",
    "        print('FALSE NEGATIVE RATE: ', round(self.fnrate, 3))\n",
    "    \n",
    "    \n",
    "    def plot_matrix(self):\n",
    "        matrix_arr = [[self.conf_matrix['TNs'], self.conf_matrix['FPs']], [self.conf_matrix['FNs'], self.conf_matrix['TPs']]]\n",
    "        plt.imshow(matrix_arr, cmap = None)\n",
    "        plt.xticks(np.arange(0, 2), ['0', '1'])\n",
    "        plt.yticks(np.arange(0, 2), ['0', '1'])\n",
    "        \n",
    "        plt.text(-0.05, 0, matrix_arr[0][0], bbox=dict(fill=False, edgecolor='red', linewidth=2)) # TNs\n",
    "        plt.text(0.95, 0, matrix_arr[0][1], bbox=dict(fill=False, edgecolor='red', linewidth=2)) # FPs\n",
    "        plt.text(-0.05, 1, matrix_arr[1][0], bbox=dict(fill=False, edgecolor='red', linewidth=2)) # FNs\n",
    "        plt.text(0.95, 1, matrix_arr[1][1], bbox=dict(fill=False, edgecolor='red', linewidth=2)) # TPs\n",
    "\n",
    "        plt.xlabel('Predictions', fontsize=18)\n",
    "        plt.ylabel('Actuals', fontsize=18)\n",
    "        plt.title('Confusion Matrix', fontsize=18)\n",
    "        plt.show()\n",
    "        \n",
    "        print(matrix_arr)\n",
    "        return\n",
    "        \n",
    "    def fit(self):\n",
    "        self.conf_matrix = {'TPs': 0, 'TNs': 0, 'FPs': 0, 'FNs': 0}\n",
    "        \n",
    "        preds = self.predict()\n",
    "        \n",
    "        for i in range(len(preds)):\n",
    "            label = self.data[i][-1]\n",
    "            pred = preds[i]\n",
    "            if label == 1 and pred == 1: # truly predicted positive\n",
    "                self.conf_matrix['TPs'] += 1\n",
    "            elif label == 0 and pred == 1: # falsely predicted positive\n",
    "                self.conf_matrix['FPs'] += 1\n",
    "            elif label == 1 and pred == 0: # falsely predicted negative\n",
    "                self.conf_matrix['FNs'] += 1\n",
    "            elif label == 0 and pred == 0: # truly predicted negative\n",
    "                self.conf_matrix['TNs'] += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "7a402c02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'TPs': 10, 'TNs': 1981, 'FPs': 6, 'FNs': 3}\n",
      " \n",
      "ACCURACY:  0.996\n",
      " \n",
      "PRECISION:  0.625\n",
      " \n",
      "RECALL:  0.769\n",
      " \n",
      "FALSE POSITIVE RATE:  0.003\n",
      " \n",
      "FALSE NEGATIVE RATE:  0.231\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1981, 6], [3, 10]]\n"
     ]
    }
   ],
   "source": [
    "cc_cm = ConfusionMatrix(modelcc, testcc)\n",
    "cc_cm.fit()\n",
    "cc_cm.print_matrix()\n",
    "cc_cm.print_metrics()\n",
    "cc_cm.plot_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "75c85557",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.2021911 , 0.86663459],\n",
       "       [0.26005507, 0.48487318]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 7. Predict on titanic dataset - https://www.kaggle.com/competitions/titanic/data\n",
    "np.random.random((2, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebce042",
   "metadata": {},
   "outputs": [],
   "source": [
    "[[]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
