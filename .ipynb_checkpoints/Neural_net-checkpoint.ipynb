{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a11a4d4a",
   "metadata": {},
   "source": [
    "# Neural Network w/ backpropagation in Python from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432a4860",
   "metadata": {},
   "source": [
    "Lecture: https://www.youtube.com/watch?v=59Hbtz7XgjM\n",
    "Post: https://cs231n.github.io/optimization-2/\n",
    "Post: https://mattmazur.com/2015/03/17/a-step-by-step-backpropagation-example/\n",
    "Video: https://www.youtube.com/watch?v=4shguqlkTDM\n",
    "Code Inspiration: https://github.com/yacineMahdid/artificial-intelligence-and-machine-learning/blob/master/deep-learning-from-scratch-python/multi_layer_perceptron.ipynb (different data, try out different activations - sigmoid, ReLu, tanh)\n",
    "Code Inspiration 2: https://machinelearningmastery.com/implement-backpropagation-algorithm-scratch-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aafcb12d",
   "metadata": {},
   "source": [
    "### Functional Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60059532",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from csv import reader\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee035d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = [[2.7810836,2.550537003, 0],\n",
    "           [1.465489372,2.362125076, 0],\n",
    "           [3.396561688,4.400293529, 0],\n",
    "           [1.38807019,1.850220317, 0],\n",
    "           [3.06407232,3.005305973, 0],\n",
    "           [7.627531214,2.759262235, 1],\n",
    "           [5.332441248,2.088626775, 1],\n",
    "           [6.922596716,1.77106367, 1],\n",
    "           [8.675418651,-0.242068655, 1],\n",
    "           [7.673756466,3.508563011, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5532f241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HIDDEN LAYER 1\n",
      "[{'params': [0.9952490707849014, 0.9987559562888128, 0.08698922299194745]}]\n",
      " \n",
      "OUTPUT LAYER\n",
      "[{'params': [0.8967199102543199, 0.12851920092515534]}, {'params': [0.8441539793936715, 0.3181463199994664]}]\n"
     ]
    }
   ],
   "source": [
    "# 1. Initialize network with weights\n",
    "\n",
    "n_hidden = 1 # number of hidden layers\n",
    "n_inputs = len(train[0][:-1]) # number of features\n",
    "n_hidden_neurons = [1, 1] # number of neurons in hidden layer\n",
    "n_outputs = 2 # number of possible outputs to be predicted\n",
    "\n",
    "def init_network(n_inputs, n_hidden, n_hidden_neurons, n_outputs):\n",
    "\n",
    "    network = []\n",
    "    \n",
    "    # number of parameters = 1 per input (features in original data) + bias = n_inputs + 1\n",
    "    # number of neurons in layer = n_hidden_neurons[i]\n",
    "    i = 0\n",
    "    for n in range(n_hidden):\n",
    "        if i == 0:\n",
    "            hidden_layer = [{'params': [np.random.rand() for n in range(n_inputs + 1)]} for n in range(n_hidden_neurons[i])]\n",
    "        else:\n",
    "            hidden_layer = [{'params': [np.random.rand() for n in range(n_hidden_neurons[i-1] + 1)]} for n in range(n_hidden_neurons[i])]\n",
    "        network.append(hidden_layer)\n",
    "        i += 1\n",
    "        \n",
    "    # number of parameters = 1 per input (neurons in previous hidden layer) + bias = n_hidden + 1\n",
    "    # number of neurons in layer = n_outputs\n",
    "    output_layer = [{'params': [np.random.rand() for n in range(n_hidden_neurons[i-1] + 1)]} for n in range(n_outputs)]\n",
    "    network.append(output_layer)\n",
    "    \n",
    "    return network\n",
    "\n",
    "def print_layers(network):\n",
    "    i = 0\n",
    "    for layer in network:\n",
    "        if i < n_hidden:\n",
    "            print(f'HIDDEN LAYER {i+1}')\n",
    "            print(layer)\n",
    "            print(' ')\n",
    "        if i == n_hidden:\n",
    "            print('OUTPUT LAYER')\n",
    "            print(layer)\n",
    "        i += 1\n",
    "        \n",
    "network = init_network(n_inputs, n_hidden, n_hidden_neurons, n_outputs)\n",
    "\n",
    "print_layers(network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5762d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activation functions\n",
    "def sigmoid(output):\n",
    "    return 1.0 / (1.0 + np.exp(-output))\n",
    "\n",
    "def ReLu(output):\n",
    "    return max(0, output)\n",
    "\n",
    "def tanh(output):\n",
    "    return (np.exp(output)-np.exp(-output))/(np.exp(output)+np.exp(-output))\n",
    "\n",
    "activation_functions = ('sigmoid', 'ReLu', 'tanh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "303d0af2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7352094192953503, 0.7610624409405787]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. Forward propagate\n",
    "\n",
    "# Calculates the output of a single neuron -> (weights * inputs) + bias\n",
    "def calc_neuron_output(params, inputs):\n",
    "    bias = params[-1]\n",
    "    output = bias\n",
    "    for i in range(len(params) - 1): # for every weight\n",
    "        output += params[i] * inputs[i]\n",
    "    return output\n",
    "\n",
    "def forward_propagate(network, inputs):\n",
    "    \n",
    "    for layer in network:\n",
    "        \n",
    "        # this list will store the activated output of each neuron to be the input of the next layer\n",
    "        # (in case the current layer is a hidden layer). Otherwise, this list will represent the outputs of the model\n",
    "        next_inputs = []\n",
    "        \n",
    "        for neuron in layer:\n",
    "            neuron_out = calc_neuron_output(neuron['params'], inputs) # linear output of neuron\n",
    "            neuron['output_activated'] = sigmoid(neuron_out) # sigmoid activation of linear output\n",
    "            next_inputs.append(neuron['output_activated'])\n",
    "            \n",
    "        inputs = next_inputs\n",
    "\n",
    "    return inputs # outputs of output layer\n",
    "\n",
    "forward_propagate(network, train[0][:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e095d180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Derivatives of activation functions\n",
    "def d_sigmoid(s):\n",
    "    return s*(1-s)\n",
    "\n",
    "def d_ReLu(r):\n",
    "    return 1 if r > 0 else 0\n",
    "\n",
    "def d_tanh(t):\n",
    "    return 1-t**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c81b581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HIDDEN LAYER 1\n",
      "[{'params': [0.9952490707849014, 0.9987559562888128, 0.08698922299194745], 'output_activated': 0.9955136711412541}]\n",
      " \n",
      "OUTPUT LAYER\n",
      "[{'params': [0.8967199102543199, 0.12851920092515534], 'output_activated': 0.7352094192953503}, {'params': [0.8441539793936715, 0.3181463199994664], 'output_activated': 0.7610624409405787}]\n"
     ]
    }
   ],
   "source": [
    "print_layers(network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e83fd4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Back propagate error\n",
    "\n",
    "# delta (error) for neuron in output layer = (y_pred-y_expected) * d_actv\n",
    "# delta (error) for neuron in hidden layers = sum(all connected weights from top layer * corresponding delta)\n",
    "\n",
    "# i is the ith layer of the network we are iterating through\n",
    "# expected_output are the expected outputs of the network (neurons in the output layer)\n",
    "##([1,0] for 0 , [0,1] for 1) (answer corresponds to the index where 1 is)\n",
    "\n",
    "def backpropagate(network, i, expected_output):\n",
    "    \n",
    "    # Base case -- backpropagation starts in output layer\n",
    "    if i == n_hidden:\n",
    "\n",
    "        for n in range(len(network[i])): # loop through each neuron in the layer i of the network (output layer)\n",
    "            neuron = network[i][n] # current neuron\n",
    "            error = neuron['output_activated'] - expected_output[n] # error for output in neuron n of output layer\n",
    "            neuron['delta'] = error * d_sigmoid(neuron['output_activated'])\n",
    "        return\n",
    "    # End of base case\n",
    "\n",
    "    errors = backpropagate(network, i + 1, expected_output)\n",
    "    \n",
    "    for n in range(len(network[i])): # loop through each neuron in the layer i of the network (hidden layer)\n",
    "        neuron = network[i][n] # current neuron\n",
    "        error = 0.0\n",
    "        for top_neuron in network[i+1]: # for each neuron in layer above\n",
    "            # (weights of top layer that the neuron output was multiplied by) * (corresponding delta)\n",
    "            error += top_neuron['params'][n] * top_neuron['delta']\n",
    "        neuron['delta'] = error * d_sigmoid(neuron['output_activated'])\n",
    "        \n",
    "    return\n",
    "            \n",
    "backpropagate(network, 0, [1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6417c4ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HIDDEN LAYER 1\n",
      "[{'params': [0.9952490707849014, 0.9987559562888128, 0.08698922299194745], 'output_activated': 0.9955136711412541, 'delta': 0.00031532880994299134}]\n",
      " \n",
      "OUTPUT LAYER\n",
      "[{'params': [0.8967199102543199, 0.12851920092515534], 'output_activated': 0.7352094192953503, 'delta': -0.0515485111832671}, {'params': [0.8441539793936715, 0.3181463199994664], 'output_activated': 0.7610624409405787, 'delta': 0.1383964665292191}]\n"
     ]
    }
   ],
   "source": [
    "print_layers(network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "9bbbab97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Train network\n",
    "\n",
    "def update_weights(network, row, lr):\n",
    "    for i in range(len(network)): # for every layer in the network\n",
    "        inputs = row[:-1] # take training inputs\n",
    "        if i != 0: # for all layers except the first\n",
    "            inputs = [neuron['output_activated'] for neuron in network[i-1]] # inputs are the output of the previous layer\n",
    "        for neuron in network[i]: # for every neuron in the layer\n",
    "            for j in range(len(inputs)): # for every input to the layer (every weight in the neuron)\n",
    "                neuron['params'][j] -= lr * neuron['delta'] * inputs[j] # weight update\n",
    "            neuron['params'][-1] -= lr * neuron['delta'] # bias update\n",
    "\n",
    "def train_network(network, training_data, lr, n_epochs):\n",
    "    \n",
    "    for n_epoch in range(n_epochs):\n",
    "        sse = 0.0\n",
    "        \n",
    "        for row in training_data:\n",
    "            output = forward_propagate(network, row)\n",
    "            expected = [0 for i in range(len(output))] # initialize to an array of 0s of same size as outputs\n",
    "            expected[row[-1]] = 1 # if actual output is 1, expected is [0,1], if 0 it is [1,0]\n",
    "            sse += sum([(expected[i]-output[i])**2 for i in range(len(expected))])\n",
    "            backpropagate(network, 0, expected)\n",
    "            update_weights(network, row, lr)\n",
    "        \n",
    "        if n_epoch % 50 == 0:\n",
    "            print('>epoch=%d, error=%.3f' % (n_epoch, sse)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44af0b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">epoch=0, error=6.269\n",
      ">epoch=10, error=5.114\n",
      ">epoch=20, error=5.104\n",
      ">epoch=30, error=5.100\n",
      ">epoch=40, error=5.092\n",
      ">epoch=50, error=5.077\n",
      ">epoch=60, error=5.039\n",
      ">epoch=70, error=4.890\n",
      ">epoch=80, error=4.188\n",
      ">epoch=90, error=3.064\n",
      ">epoch=100, error=2.154\n",
      ">epoch=110, error=1.559\n",
      ">epoch=120, error=1.179\n",
      ">epoch=130, error=0.929\n",
      ">epoch=140, error=0.756\n",
      ">epoch=150, error=0.633\n",
      ">epoch=160, error=0.541\n",
      ">epoch=170, error=0.470\n",
      ">epoch=180, error=0.415\n",
      ">epoch=190, error=0.370\n",
      ">epoch=200, error=0.334\n",
      ">epoch=210, error=0.303\n",
      ">epoch=220, error=0.277\n",
      ">epoch=230, error=0.256\n",
      ">epoch=240, error=0.237\n",
      ">epoch=250, error=0.220\n",
      ">epoch=260, error=0.206\n",
      ">epoch=270, error=0.193\n",
      ">epoch=280, error=0.182\n",
      ">epoch=290, error=0.172\n",
      ">epoch=300, error=0.163\n",
      ">epoch=310, error=0.154\n",
      ">epoch=320, error=0.147\n",
      ">epoch=330, error=0.140\n",
      ">epoch=340, error=0.134\n",
      ">epoch=350, error=0.128\n",
      ">epoch=360, error=0.123\n",
      ">epoch=370, error=0.118\n",
      ">epoch=380, error=0.113\n",
      ">epoch=390, error=0.109\n",
      ">epoch=400, error=0.105\n",
      ">epoch=410, error=0.102\n",
      ">epoch=420, error=0.098\n",
      ">epoch=430, error=0.095\n",
      ">epoch=440, error=0.092\n",
      ">epoch=450, error=0.089\n",
      ">epoch=460, error=0.086\n",
      ">epoch=470, error=0.084\n",
      ">epoch=480, error=0.082\n",
      ">epoch=490, error=0.079\n"
     ]
    }
   ],
   "source": [
    "def backprop(training_data, lr, n_epochs, n_inputs, n_hidden, n_hidden_neurons, n_outputs):\n",
    "    model = init_network(n_inputs, n_hidden, n_hidden_neurons, n_outputs)\n",
    "    train_network(model, training_data, lr, n_epochs)\n",
    "    \n",
    "    return model\n",
    "    \n",
    "lr = 0.2\n",
    "training_data = train\n",
    "n_epochs = 501\n",
    "\n",
    "model = backprop(training_data, lr, n_epochs, n_inputs, n_hidden, n_hidden_neurons, n_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "897c88a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### 5. Predict\n",
    "def predict(model, train):\n",
    "    \n",
    "    preds = [] # stores the predictions of all data points of the training data\n",
    "    \n",
    "    for row in training_data:\n",
    "        label = row[-1]\n",
    "        features = row[:-1]\n",
    "        outputs = forward_propagate(model, features)\n",
    "        pred = outputs.index(max(outputs))\n",
    "        preds.append(pred)\n",
    "    \n",
    "    return preds\n",
    "\n",
    "predict(model, train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ff529cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a csv file\n",
    "def load_csv(filename):\n",
    "    dataset = list()\n",
    "    with open(filename, 'r') as file:\n",
    "        csv_reader = reader(file)\n",
    "        for row in csv_reader:\n",
    "            if not row:\n",
    "                continue\n",
    "            dataset.append(row)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "95689dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">epoch=0, error=129.804\n",
      ">epoch=10, error=50.141\n",
      ">epoch=20, error=49.921\n",
      ">epoch=30, error=49.780\n",
      ">epoch=40, error=49.324\n",
      ">epoch=50, error=48.959\n",
      ">epoch=60, error=48.749\n",
      ">epoch=70, error=48.497\n",
      ">epoch=80, error=48.132\n",
      ">epoch=90, error=47.572\n",
      ">epoch=100, error=46.635\n",
      ">epoch=110, error=44.941\n",
      ">epoch=120, error=41.760\n",
      ">epoch=130, error=36.786\n",
      ">epoch=140, error=32.177\n",
      ">epoch=150, error=29.220\n",
      ">epoch=160, error=27.263\n",
      ">epoch=170, error=25.943\n",
      ">epoch=180, error=25.022\n",
      ">epoch=190, error=24.348\n",
      ">epoch=200, error=23.828\n",
      ">epoch=210, error=23.410\n",
      ">epoch=220, error=23.065\n",
      ">epoch=230, error=22.774\n",
      ">epoch=240, error=22.525\n",
      ">epoch=250, error=22.310\n",
      ">epoch=260, error=22.122\n",
      ">epoch=270, error=21.957\n",
      ">epoch=280, error=21.811\n",
      ">epoch=290, error=21.682\n",
      ">epoch=300, error=21.566\n",
      ">epoch=310, error=21.462\n",
      ">epoch=320, error=21.369\n",
      ">epoch=330, error=21.285\n",
      ">epoch=340, error=21.209\n",
      ">epoch=350, error=21.140\n",
      ">epoch=360, error=21.076\n",
      ">epoch=370, error=21.019\n",
      ">epoch=380, error=20.966\n",
      ">epoch=390, error=20.917\n",
      ">epoch=400, error=20.873\n",
      ">epoch=410, error=20.831\n",
      ">epoch=420, error=20.793\n",
      ">epoch=430, error=20.758\n",
      ">epoch=440, error=20.725\n",
      ">epoch=450, error=20.694\n",
      ">epoch=460, error=20.666\n",
      ">epoch=470, error=20.639\n",
      ">epoch=480, error=20.614\n",
      ">epoch=490, error=20.591\n"
     ]
    }
   ],
   "source": [
    "# 6. Predict on fraud detection dataset - https://www.kaggle.com/datasets/whenamancodes/fraud-detection?resource=download\n",
    "\n",
    "ccard_data = load_csv('creditcard.csv')\n",
    "ccard_data_mod = []\n",
    "i = 0\n",
    "for row in ccard_data: # take only first 2 features and output, convert from string to float/integer\n",
    "    if i != 0:\n",
    "        new_row = row[1:3]\n",
    "        for j in range(len(new_row)):\n",
    "            new_row[j] = float(new_row[j])\n",
    "        new_row.append(int(row[30]))\n",
    "\n",
    "        ccard_data_mod.append(new_row)\n",
    "    i += 1\n",
    "\n",
    "traincc = ccard_data_mod[:8000]\n",
    "testcc = ccard_data_mod[8000:10000]\n",
    "\n",
    "lr = 0.1\n",
    "training_data = traincc\n",
    "n_epochscc = 501\n",
    "\n",
    "n_hiddencc = 1 # number of hidden layers\n",
    "n_inputscc = len(traincc[0][:-1]) # number of features\n",
    "n_hidden_neuronscc = [1,1] # number of neurons in hidden layer\n",
    "n_outputscc = 2 # number of possible outputs to be predicted\n",
    "\n",
    "modelcc = backprop(traincc, lr, n_epochscc, n_inputscc, n_hiddencc, n_hidden_neuronscc, n_outputscc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e285659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "class ConfusionMatrix:\n",
    "    \n",
    "    def __init__(self, modelcm, data):\n",
    "        self.model = modelcm\n",
    "        self.data = data\n",
    "        self.conf_matrix = None\n",
    "        \n",
    "        # METRICS\n",
    "        self.accuracy = 0.0\n",
    "        self.precision = 0.0\n",
    "        self.recall = 0.0\n",
    "        self.fprate = 0.0\n",
    "        self.fnrate = 0.0\n",
    "        \n",
    "    def predict(self):\n",
    "    \n",
    "        preds = [] # stores the predictions of all data points of the training data\n",
    "\n",
    "        for row in self.data:\n",
    "            label = row[-1]\n",
    "            features = row[:-1]\n",
    "            outputs = forward_propagate(self.model, features)\n",
    "            pred = outputs.index(max(outputs))\n",
    "            preds.append(pred)\n",
    "\n",
    "        return preds\n",
    "    \n",
    "    def print_matrix(self):\n",
    "        print(self.conf_matrix)\n",
    "        print(' ')\n",
    "        \n",
    "    def print_metrics(self):\n",
    "        # Accuracy (what fraction does it get right) = (# TP + # TN) / Total\n",
    "        self.accuracy = (self.conf_matrix['TPs'] + self.conf_matrix['TNs']) / sum(self.conf_matrix.values())\n",
    "        print('ACCURACY: ', round(self.accuracy, 3))\n",
    "        print(' ')\n",
    "        \n",
    "        # Precision (when it says 1, how often is it right) = # TP / (# TP + # FP)\n",
    "        self.precision = self.conf_matrix['TPs'] / (self.conf_matrix['TPs'] + self.conf_matrix['FPs'])\n",
    "        print('PRECISION: ', round(self.precision, 3))\n",
    "        print(' ')\n",
    "        \n",
    "        # Recall (what fraction of 1s does it get right) = # TP / (# TP + # FN)\n",
    "        self.recall = self.conf_matrix['TPs'] / (self.conf_matrix['TPs'] + self.conf_matrix['FNs'])\n",
    "        print('RECALL: ', round(self.recall, 3))\n",
    "        print(' ')\n",
    "        \n",
    "        # False positive rate (what fraction of 0s are called 1s) = # FP / (# FP + # TN)\n",
    "        self.fprate = self.conf_matrix['FPs'] / (self.conf_matrix['FPs'] + self.conf_matrix['TNs'])\n",
    "        print('FALSE POSITIVE RATE: ', round(self.fprate, 3))\n",
    "        print(' ')\n",
    "        \n",
    "        # False negative rate (what fraction of 1s are called 0s) = # FN / (# TP + # FN)\n",
    "        self.fnrate = self.conf_matrix['FNs'] / (self.conf_matrix['TPs'] + self.conf_matrix['FNs'])\n",
    "        print('FALSE NEGATIVE RATE: ', round(self.fnrate, 3))\n",
    "    \n",
    "    \n",
    "    def plot_matrix(self):\n",
    "        matrix_arr = [[self.conf_matrix['TNs'], self.conf_matrix['FPs']], [self.conf_matrix['FNs'], self.conf_matrix['TPs']]]\n",
    "        plt.imshow(matrix_arr, cmap = 'coolwarm', alpha = 0.5)\n",
    "        plt.xticks(np.arange(0, 2), ['0', '1'])\n",
    "        plt.yticks(np.arange(0, 2), ['0', '1'])\n",
    "        \n",
    "        plt.text(-0.1, 0, matrix_arr[0][0], fontsize = 14) # TNs\n",
    "        plt.text(0.95, 0, matrix_arr[0][1], fontsize = 14) # FPs\n",
    "        plt.text(-0.1, 1, matrix_arr[1][0], fontsize = 14) # FNs\n",
    "        plt.text(0.95, 1, matrix_arr[1][1], fontsize = 14) # TPs\n",
    "\n",
    "        plt.xlabel('Predictions', fontsize=18)\n",
    "        plt.ylabel('Actuals', fontsize=18)\n",
    "        plt.title('Confusion Matrix', fontsize=18)\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "    def fit(self):\n",
    "        self.conf_matrix = {'TPs': 0, 'TNs': 0, 'FPs': 0, 'FNs': 0}\n",
    "        \n",
    "        preds = self.predict()\n",
    "        \n",
    "        for i in range(len(preds)):\n",
    "            label = self.data[i][-1]\n",
    "            pred = preds[i]\n",
    "            if label == 1 and pred == 1: # truly predicted positive\n",
    "                self.conf_matrix['TPs'] += 1\n",
    "            elif label == 0 and pred == 1: # falsely predicted positive\n",
    "                self.conf_matrix['FPs'] += 1\n",
    "            elif label == 1 and pred == 0: # falsely predicted negative\n",
    "                self.conf_matrix['FNs'] += 1\n",
    "            elif label == 0 and pred == 0: # truly predicted negative\n",
    "                self.conf_matrix['TNs'] += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4861499f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY:  0.996\n",
      " \n",
      "PRECISION:  0.625\n",
      " \n",
      "RECALL:  0.769\n",
      " \n",
      "FALSE POSITIVE RATE:  0.003\n",
      " \n",
      "FALSE NEGATIVE RATE:  0.231\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cc_cm = ConfusionMatrix(modelcc, testcc)\n",
    "cc_cm.fit()\n",
    "cc_cm.print_metrics()\n",
    "cc_cm.plot_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "48854f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Predict on titanic dataset - https://www.kaggle.com/competitions/titanic/data\n",
    "titanic_train = load_csv('titanic_train.csv')\n",
    "\n",
    "def modify_titanic(titanic_data):\n",
    "    # take max and min of variables to be normalized\n",
    "    age_min = 100\n",
    "    age_max = 0\n",
    "    sibsp_min = 100\n",
    "    sibsp_max = 0\n",
    "    parch_min = 100\n",
    "    parch_max = 0\n",
    "    fare_min = 100.0\n",
    "    fare_max = 0.0\n",
    "\n",
    "    j = 0\n",
    "    for row in titanic_data:\n",
    "        if j != 0:\n",
    "            age = int(row[5]) if row[5].isdigit() else age_min\n",
    "            if age < age_min:\n",
    "                age_min = age\n",
    "            if age > age_max:\n",
    "                age_max = age\n",
    "\n",
    "            sibsp = int(row[6]) if row[6].isdigit() else sibsp_min\n",
    "            if sibsp < sibsp_min:\n",
    "                sibsp_min = sibsp\n",
    "            if sibsp > sibsp_max:\n",
    "                sibsp_max = sibsp\n",
    "\n",
    "            parch = int(row[7]) if row[7].isdigit() else parch_min\n",
    "            if parch < parch_min:\n",
    "                parch_min = parch\n",
    "            if parch > parch_max:\n",
    "                parch_max = parch\n",
    "\n",
    "            fare = float(row[9]) if row[9].isdigit() else fare_min\n",
    "            if fare < fare_min:\n",
    "                fare_min = fare\n",
    "            if fare > fare_max:\n",
    "                fare_max = fare\n",
    "        j += 1\n",
    "    \n",
    "    titanic_mod = []\n",
    "\n",
    "    for i in range(len(titanic_data)): # take only first 2 features and output, convert from string to float/integer\n",
    "\n",
    "        if i != 0:\n",
    "\n",
    "            row = titanic_data[i]\n",
    "            new_row = []\n",
    "\n",
    "            gender = 1 if row[4] == 'male' else 0\n",
    "            new_row.append(gender)\n",
    "\n",
    "            # scale 'Age' variable (row[5]) to [0,1] range and append to new_row\n",
    "            if row[5].isdigit():\n",
    "                age = int(row[5])\n",
    "                age_scaled = (age - age_min) / (age_max - age_min)\n",
    "                new_row.append(age_scaled)\n",
    "\n",
    "            # scale 'SibSp' variable (row[6]) and append to new_row\n",
    "            if row[6].isdigit():\n",
    "                sibsp = int(row[6])\n",
    "                sibsp_scaled = (sibsp - sibsp_min) / (sibsp_max - sibsp_min)\n",
    "                new_row.append(sibsp_scaled)\n",
    "\n",
    "            # scale 'Parch' variable (row[7]) and append to new_row\n",
    "            if row[7].isdigit():\n",
    "                parch = int(row[7])\n",
    "                parch_scaled = (parch - parch_min) / (parch_max - parch_min)\n",
    "                new_row.append(parch_scaled)\n",
    "\n",
    "            # scale 'Fare' variable (row[9]) and append to new_row\n",
    "            if row[9].replace('.','',1).isdigit():\n",
    "                fare = float(row[9])\n",
    "                fare_scaled = (fare - fare_min) / (fare_max - fare_min)\n",
    "                new_row.append(fare_scaled)\n",
    "\n",
    "            # append label ('Survived') (row[1]) to new_row\n",
    "            new_row.append(int(row[1]))\n",
    "\n",
    "            if row[5].isdigit() and row[6].isdigit() and row[7].isdigit() and row[9].replace('.','',1).isdigit():\n",
    "                titanic_mod.append(new_row)\n",
    "                \n",
    "    return titanic_mod\n",
    "\n",
    "titanic_train_mod = modify_titanic(titanic_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "0ae2e3d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">epoch=0, error=350.708\n",
      ">epoch=50, error=214.027\n",
      ">epoch=100, error=207.283\n",
      ">epoch=150, error=201.688\n",
      ">epoch=200, error=197.801\n",
      ">epoch=250, error=195.342\n",
      ">epoch=300, error=193.298\n",
      ">epoch=350, error=191.527\n",
      ">epoch=400, error=189.995\n",
      ">epoch=450, error=188.711\n",
      ">epoch=500, error=187.500\n"
     ]
    }
   ],
   "source": [
    "lr = 0.2\n",
    "training_data = titanic_train_mod\n",
    "n_epochs_titanic = 501\n",
    "\n",
    "n_hidden_titanic = 1 # number of hidden layers\n",
    "n_inputs_titanic = len(titanic_train_mod[0][:-1]) # number of features\n",
    "n_hidden_neurons_titanic = [5,1] # number of neurons in hidden layer\n",
    "n_outputs_titanic = 2 # number of possible outputs to be predicted\n",
    "\n",
    "model_titanic = backprop(titanic_train_mod, lr, n_epochs_titanic, n_inputs_titanic, n_hidden_titanic, n_hidden_neurons_titanic, n_outputs_titanic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "421f2cfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY:  0.826\n",
      " \n",
      "PRECISION:  0.814\n",
      " \n",
      "RECALL:  0.745\n",
      " \n",
      "FALSE POSITIVE RATE:  0.118\n",
      " \n",
      "FALSE NEGATIVE RATE:  0.255\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "conf_matrix_titanic = ConfusionMatrix(model_titanic, titanic_train_mod)\n",
    "conf_matrix_titanic.fit()\n",
    "conf_matrix_titanic.print_metrics()\n",
    "conf_matrix_titanic.plot_matrix()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
