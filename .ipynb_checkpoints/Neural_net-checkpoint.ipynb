{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a11a4d4a",
   "metadata": {},
   "source": [
    "# Neural Network w/ backpropagation in Python from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432a4860",
   "metadata": {},
   "source": [
    "Lecture: https://www.youtube.com/watch?v=59Hbtz7XgjM\n",
    "Post: https://cs231n.github.io/optimization-2/\n",
    "Post: https://mattmazur.com/2015/03/17/a-step-by-step-backpropagation-example/\n",
    "Video: https://www.youtube.com/watch?v=4shguqlkTDM\n",
    "Code Inspiration: https://github.com/yacineMahdid/artificial-intelligence-and-machine-learning/blob/master/deep-learning-from-scratch-python/multi_layer_perceptron.ipynb (different data, try out different activations - sigmoid, ReLu, tanh)\n",
    "Code Inspiration 2: https://machinelearningmastery.com/implement-backpropagation-algorithm-scratch-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aafcb12d",
   "metadata": {},
   "source": [
    "### Functional Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60059532",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from csv import reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee035d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = [[2.7810836,2.550537003, 0],\n",
    "           [1.465489372,2.362125076, 0],\n",
    "           [3.396561688,4.400293529, 0],\n",
    "           [1.38807019,1.850220317, 0],\n",
    "           [3.06407232,3.005305973, 0],\n",
    "           [7.627531214,2.759262235, 1],\n",
    "           [5.332441248,2.088626775, 1],\n",
    "           [6.922596716,1.77106367, 1],\n",
    "           [8.675418651,-0.242068655, 1],\n",
    "           [7.673756466,3.508563011, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5532f241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HIDDEN LAYER 1\n",
      "[{'params': [0.8485114470477703, 0.17374294525312173, 0.49150058797919804]}]\n",
      " \n",
      "OUTPUT LAYER\n",
      "[{'params': [0.6996503849546813, 0.7626411539657336]}, {'params': [0.9528642831796602, 0.005538027976710769]}]\n"
     ]
    }
   ],
   "source": [
    "# 1. Initialize network with weights\n",
    "\n",
    "n_hidden = 1 # number of hidden layers\n",
    "n_inputs = len(train[0][:-1]) # number of features\n",
    "n_hidden_neurons = [1, 1] # number of neurons in hidden layer\n",
    "n_outputs = 2 # number of possible outputs to be predicted\n",
    "\n",
    "def init_network(n_inputs, n_hidden, n_hidden_neurons, n_outputs):\n",
    "\n",
    "    network = []\n",
    "    \n",
    "    # number of parameters = 1 per input (features in original data) + bias = n_inputs + 1\n",
    "    # number of neurons in layer = n_hidden_neurons[i]\n",
    "    i = 0\n",
    "    for n in range(n_hidden):\n",
    "        if i == 0:\n",
    "            hidden_layer = [{'params': [np.random.rand() for n in range(n_inputs + 1)]} for n in range(n_hidden_neurons[i])]\n",
    "        else:\n",
    "            hidden_layer = [{'params': [np.random.rand() for n in range(n_hidden_neurons[i-1] + 1)]} for n in range(n_hidden_neurons[i])]\n",
    "        network.append(hidden_layer)\n",
    "        i += 1\n",
    "        \n",
    "    # number of parameters = 1 per input (neurons in previous hidden layer) + bias = n_hidden + 1\n",
    "    # number of neurons in layer = n_outputs\n",
    "    output_layer = [{'params': [np.random.rand() for n in range(n_hidden_neurons[i-1] + 1)]} for n in range(n_outputs)]\n",
    "    network.append(output_layer)\n",
    "    \n",
    "    return network\n",
    "\n",
    "def print_layers(network):\n",
    "    i = 0\n",
    "    for layer in network:\n",
    "        if i < n_hidden:\n",
    "            print(f'HIDDEN LAYER {i+1}')\n",
    "            print(layer)\n",
    "            print(' ')\n",
    "        if i == n_hidden:\n",
    "            print('OUTPUT LAYER')\n",
    "            print(layer)\n",
    "        i += 1\n",
    "        \n",
    "network = init_network(n_inputs, n_hidden, n_hidden_neurons, n_outputs)\n",
    "\n",
    "print_layers(network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5762d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activation functions\n",
    "def sigmoid(output):\n",
    "    return 1.0 / (1.0 + np.exp(-output))\n",
    "\n",
    "def ReLu(output):\n",
    "    return max(0, output)\n",
    "\n",
    "def tanh(output):\n",
    "    return (np.exp(output)-np.exp(-output))/(np.exp(output)+np.exp(-output))\n",
    "\n",
    "activation_functions = ('sigmoid', 'ReLu', 'tanh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "303d0af2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.808031516804913, 0.715922515183487]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. Forward propagate\n",
    "\n",
    "# Calculates the output of a single neuron -> (weights * inputs) + bias\n",
    "def calc_neuron_output(params, inputs):\n",
    "    bias = params[-1]\n",
    "    output = bias\n",
    "    for i in range(len(params) - 1): # for every weight\n",
    "        output += params[i] * inputs[i]\n",
    "    return output\n",
    "\n",
    "def forward_propagate(network, inputs):\n",
    "    \n",
    "    for layer in network:\n",
    "        \n",
    "        # this list will store the activated output of each neuron to be the input of the next layer\n",
    "        # (in case the current layer is a hidden layer). Otherwise, this list will represent the outputs of the model\n",
    "        next_inputs = []\n",
    "        \n",
    "        for neuron in layer:\n",
    "            neuron_out = calc_neuron_output(neuron['params'], inputs) # linear output of neuron\n",
    "            neuron['output_activated'] = sigmoid(neuron_out) # sigmoid activation of linear output\n",
    "            next_inputs.append(neuron['output_activated'])\n",
    "            \n",
    "        inputs = next_inputs\n",
    "\n",
    "    return inputs # outputs of output layer\n",
    "\n",
    "forward_propagate(network, train[0][:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e095d180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Derivatives of activation functions\n",
    "def d_sigmoid(s):\n",
    "    return s*(1-s)\n",
    "\n",
    "def d_ReLu(r):\n",
    "    return 1 if r > 0 else 0\n",
    "\n",
    "def d_tanh(t):\n",
    "    return 1-t**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c81b581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HIDDEN LAYER 1\n",
      "[{'params': [0.8485114470477703, 0.17374294525312173, 0.49150058797919804], 'output_activated': 0.9642368756174116}]\n",
      " \n",
      "OUTPUT LAYER\n",
      "[{'params': [0.6996503849546813, 0.7626411539657336], 'output_activated': 0.808031516804913}, {'params': [0.9528642831796602, 0.005538027976710769], 'output_activated': 0.715922515183487}]\n"
     ]
    }
   ],
   "source": [
    "print_layers(network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e83fd4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Back propagate error\n",
    "\n",
    "# delta (error) for neuron in output layer = (y_pred-y_expected) * d_actv\n",
    "# delta (error) for neuron in hidden layers = sum(all connected weights from top layer * corresponding delta)\n",
    "\n",
    "# i is the ith layer of the network we are iterating through\n",
    "# expected_output are the expected outputs of the network (neurons in the output layer)\n",
    "##([1,0] for 0 , [0,1] for 1) (answer corresponds to the index where 1 is)\n",
    "\n",
    "def backpropagate(network, i, expected_output):\n",
    "    \n",
    "    # Base case -- backpropagation starts in output layer\n",
    "    if i == n_hidden:\n",
    "\n",
    "        for n in range(len(network[i])): # loop through each neuron in the layer i of the network (output layer)\n",
    "            neuron = network[i][n] # current neuron\n",
    "            error = neuron['output_activated'] - expected_output[n] # error for output in neuron n of output layer\n",
    "            neuron['delta'] = error * d_sigmoid(neuron['output_activated'])\n",
    "        return\n",
    "    # End of base case\n",
    "\n",
    "    errors = backpropagate(network, i + 1, expected_output)\n",
    "    \n",
    "    for n in range(len(network[i])): # loop through each neuron in the layer i of the network (hidden layer)\n",
    "        neuron = network[i][n] # current neuron\n",
    "        error = 0.0\n",
    "        for top_neuron in network[i+1]: # for each neuron in layer above\n",
    "            # (weights of top layer that the neuron output was multiplied by) * (corresponding delta)\n",
    "            error += top_neuron['params'][n] * top_neuron['delta']\n",
    "        neuron['delta'] = error * d_sigmoid(neuron['output_activated'])\n",
    "        \n",
    "    return\n",
    "            \n",
    "backpropagate(network, 0, [1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6417c4ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HIDDEN LAYER 1\n",
      "[{'params': [0.8485114470477703, 0.17374294525312173, 0.49150058797919804], 'output_activated': 0.9642368756174116, 'delta': 0.004065871017771854}]\n",
      " \n",
      "OUTPUT LAYER\n",
      "[{'params': [0.6996503849546813, 0.7626411539657336], 'output_activated': 0.808031516804913, 'delta': -0.029777495474596658}, {'params': [0.9528642831796602, 0.005538027976710769], 'output_activated': 0.715922515183487, 'delta': 0.14560250801902794}]\n"
     ]
    }
   ],
   "source": [
    "print_layers(network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9bbbab97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Train network\n",
    "\n",
    "def update_weights(network, row, lr):\n",
    "    for i in range(len(network)): # for every layer in the network\n",
    "        inputs = row[:-1] # take training inputs\n",
    "        if i != 0: # for all layers except the first\n",
    "            inputs = [neuron['output_activated'] for neuron in network[i-1]] # inputs are the output of the previous layer\n",
    "        for neuron in network[i]: # for every neuron in the layer\n",
    "            for j in range(len(inputs)): # for every input to the layer (every weight in the neuron)\n",
    "                neuron['params'][j] -= lr * neuron['delta'] * inputs[j] # weight update\n",
    "            neuron['params'][-1] -= lr * neuron['delta'] # bias update\n",
    "\n",
    "def train_network(network, training_data, lr, n_epochs):\n",
    "    \n",
    "    for n_epoch in range(n_epochs):\n",
    "        sse = 0.0\n",
    "        \n",
    "        for row in training_data:\n",
    "            output = forward_propagate(network, row)\n",
    "            expected = [0 for i in range(len(output))] # initialize to an array of 0s of same size as outputs\n",
    "            expected[row[-1]] = 1 # if actual output is 1, expected is [0,1], if 0 it is [1,0]\n",
    "            sse += sum([(expected[i]-output[i])**2 for i in range(len(expected))])\n",
    "            backpropagate(network, 0, expected)\n",
    "            update_weights(network, row, lr)\n",
    "        \n",
    "        if n_epoch % 10 == 0:\n",
    "            print('>epoch=%d, error=%.3f' % (n_epoch, sse)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44af0b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">epoch=0, error=6.361\n",
      ">epoch=10, error=5.136\n",
      ">epoch=20, error=5.118\n",
      ">epoch=30, error=5.117\n",
      ">epoch=40, error=5.116\n",
      ">epoch=50, error=5.114\n",
      ">epoch=60, error=5.112\n",
      ">epoch=70, error=5.109\n",
      ">epoch=80, error=5.105\n",
      ">epoch=90, error=5.099\n",
      ">epoch=100, error=5.090\n",
      ">epoch=110, error=5.071\n",
      ">epoch=120, error=5.012\n",
      ">epoch=130, error=4.658\n",
      ">epoch=140, error=3.685\n",
      ">epoch=150, error=2.620\n",
      ">epoch=160, error=1.858\n",
      ">epoch=170, error=1.371\n",
      ">epoch=180, error=1.056\n",
      ">epoch=190, error=0.845\n",
      ">epoch=200, error=0.697\n",
      ">epoch=210, error=0.589\n",
      ">epoch=220, error=0.507\n",
      ">epoch=230, error=0.444\n",
      ">epoch=240, error=0.394\n",
      ">epoch=250, error=0.353\n",
      ">epoch=260, error=0.319\n",
      ">epoch=270, error=0.291\n",
      ">epoch=280, error=0.267\n",
      ">epoch=290, error=0.247\n",
      ">epoch=300, error=0.229\n",
      ">epoch=310, error=0.214\n",
      ">epoch=320, error=0.200\n",
      ">epoch=330, error=0.188\n",
      ">epoch=340, error=0.177\n",
      ">epoch=350, error=0.167\n",
      ">epoch=360, error=0.159\n",
      ">epoch=370, error=0.151\n",
      ">epoch=380, error=0.144\n",
      ">epoch=390, error=0.137\n",
      ">epoch=400, error=0.131\n",
      ">epoch=410, error=0.126\n",
      ">epoch=420, error=0.120\n",
      ">epoch=430, error=0.116\n",
      ">epoch=440, error=0.111\n",
      ">epoch=450, error=0.107\n",
      ">epoch=460, error=0.104\n",
      ">epoch=470, error=0.100\n",
      ">epoch=480, error=0.097\n",
      ">epoch=490, error=0.094\n"
     ]
    }
   ],
   "source": [
    "def backprop(training_data, lr, n_epochs, n_inputs, n_hidden, n_hidden_neurons, n_outputs):\n",
    "    model = init_network(n_inputs, n_hidden, n_hidden_neurons, n_outputs)\n",
    "    train_network(model, training_data, lr, n_epochs)\n",
    "    \n",
    "    return model\n",
    "    \n",
    "lr = 0.2\n",
    "training_data = train\n",
    "n_epochs = 500\n",
    "\n",
    "model = backprop(training_data, lr, n_epochs, n_inputs, n_hidden, n_hidden_neurons, n_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "897c88a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### 5. Predict\n",
    "def predict(model, train):\n",
    "    \n",
    "    preds = [] # stores the predictions of all data points of the training data\n",
    "    \n",
    "    for row in training_data:\n",
    "        label = row[-1]\n",
    "        features = row[:-1]\n",
    "        outputs = forward_propagate(model, features)\n",
    "        pred = outputs.index(max(outputs))\n",
    "        preds.append(pred)\n",
    "    \n",
    "    return preds\n",
    "\n",
    "predict(model, train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ff529cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a csv file\n",
    "def load_csv(filename):\n",
    "    dataset = list()\n",
    "    with open(filename, 'r') as file:\n",
    "        csv_reader = reader(file)\n",
    "        for row in csv_reader:\n",
    "            if not row:\n",
    "                continue\n",
    "            dataset.append(row)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "95689dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">epoch=0, error=116.986\n",
      ">epoch=10, error=50.194\n",
      ">epoch=20, error=49.965\n",
      ">epoch=30, error=49.867\n",
      ">epoch=40, error=49.701\n",
      ">epoch=50, error=49.284\n",
      ">epoch=60, error=49.055\n",
      ">epoch=70, error=48.903\n",
      ">epoch=80, error=48.730\n",
      ">epoch=90, error=48.488\n",
      ">epoch=100, error=48.132\n",
      ">epoch=110, error=47.580\n",
      ">epoch=120, error=46.655\n",
      ">epoch=130, error=44.975\n",
      ">epoch=140, error=41.818\n",
      ">epoch=150, error=36.870\n",
      ">epoch=160, error=32.243\n",
      ">epoch=170, error=29.271\n",
      ">epoch=180, error=27.303\n",
      ">epoch=190, error=25.972\n",
      ">epoch=200, error=25.044\n",
      ">epoch=210, error=24.366\n",
      ">epoch=220, error=23.843\n",
      ">epoch=230, error=23.423\n",
      ">epoch=240, error=23.076\n",
      ">epoch=250, error=22.784\n",
      ">epoch=260, error=22.534\n",
      ">epoch=270, error=22.317\n",
      ">epoch=280, error=22.129\n",
      ">epoch=290, error=21.963\n",
      ">epoch=300, error=21.817\n",
      ">epoch=310, error=21.687\n",
      ">epoch=320, error=21.571\n",
      ">epoch=330, error=21.467\n",
      ">epoch=340, error=21.373\n",
      ">epoch=350, error=21.288\n",
      ">epoch=360, error=21.212\n",
      ">epoch=370, error=21.142\n",
      ">epoch=380, error=21.079\n",
      ">epoch=390, error=21.021\n",
      ">epoch=400, error=20.968\n",
      ">epoch=410, error=20.919\n",
      ">epoch=420, error=20.874\n",
      ">epoch=430, error=20.833\n",
      ">epoch=440, error=20.795\n",
      ">epoch=450, error=20.759\n",
      ">epoch=460, error=20.726\n",
      ">epoch=470, error=20.696\n",
      ">epoch=480, error=20.667\n",
      ">epoch=490, error=20.640\n"
     ]
    }
   ],
   "source": [
    "# 6. Predict on fraud detection dataset - https://www.kaggle.com/datasets/whenamancodes/fraud-detection?resource=download\n",
    "\n",
    "ccard_data = load_csv('creditcard.csv')\n",
    "ccard_data_mod = []\n",
    "i = 0\n",
    "for row in ccard_data: # take only first 2 features and output, convert from string to float/integer\n",
    "    if i != 0:\n",
    "        new_row = row[1:3]\n",
    "        for j in range(len(new_row)):\n",
    "            new_row[j] = float(new_row[j])\n",
    "        new_row.append(int(row[30]))\n",
    "\n",
    "        ccard_data_mod.append(new_row)\n",
    "    i += 1\n",
    "\n",
    "traincc = ccard_data_mod[:8000]\n",
    "testcc = ccard_data_mod[8000:10000]\n",
    "\n",
    "lr = 0.1\n",
    "training_data = traincc\n",
    "n_epochscc = 500\n",
    "\n",
    "n_hiddencc = 1 # number of hidden layers\n",
    "n_inputscc = len(traincc[0][:-1]) # number of features\n",
    "n_hidden_neuronscc = [1,1] # number of neurons in hidden layer\n",
    "n_outputscc = 2 # number of possible outputs to be predicted\n",
    "\n",
    "modelcc = backprop(traincc, lr, n_epochscc, n_inputscc, n_hiddencc, n_hidden_neuronscc, n_outputscc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4edac1e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'TPs': 15, 'TNs': 7975, 'FPs': 0, 'FNs': 10}\n"
     ]
    }
   ],
   "source": [
    "# Check accuracy in training data\n",
    "preds = predict(modelcc, traincc)\n",
    "confusion_matrix = {'TPs': 0, 'TNs': 0, 'FPs': 0, 'FNs': 0}\n",
    "\n",
    "for i in range(len(preds)):\n",
    "    label = traincc[i][-1]\n",
    "    pred = preds[i]\n",
    "    if label == 1 and pred == 1: # truly predicted positive\n",
    "        confusion_matrix['TPs'] += 1\n",
    "    elif label == 0 and pred == 1: # falsely predicted positive\n",
    "        confusion_matrix['FPs'] += 1\n",
    "    elif label == 1 and pred == 0: # falsely predicted negative\n",
    "        confusion_matrix['FNs'] += 1\n",
    "    elif label == 0 and pred == 0: # truly predicted negative\n",
    "        confusion_matrix['TNs'] += 1\n",
    "\n",
    "print(confusion_matrix)\n",
    "\n",
    "# Make class for confusion matrix. In it have accuracy, precision, recall, false positive rate, false negative rate\n",
    "# Create confusion matrix for the training set and calculate measures\n",
    "\n",
    "# Create confusion matrix for the test set and calculate measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5e285659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Predict on titanic dataset - https://www.kaggle.com/competitions/titanic/data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fcb94aa",
   "metadata": {},
   "source": [
    "### OOP Implementation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
