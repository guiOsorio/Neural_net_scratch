{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a11a4d4a",
   "metadata": {},
   "source": [
    "# Neural Network w/ backpropagation in Python from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432a4860",
   "metadata": {},
   "source": [
    "Lecture: https://www.youtube.com/watch?v=59Hbtz7XgjM\n",
    "Post: https://cs231n.github.io/optimization-2/\n",
    "Post: https://mattmazur.com/2015/03/17/a-step-by-step-backpropagation-example/\n",
    "Video: https://www.youtube.com/watch?v=4shguqlkTDM\n",
    "Code Inspiration: https://github.com/yacineMahdid/artificial-intelligence-and-machine-learning/blob/master/deep-learning-from-scratch-python/multi_layer_perceptron.ipynb (different data, try out different activations - sigmoid, ReLu, tanh)\n",
    "Code Inspiration 2: https://machinelearningmastery.com/implement-backpropagation-algorithm-scratch-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aafcb12d",
   "metadata": {},
   "source": [
    "### Functional Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "60059532",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee035d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = [[2.7810836,2.550537003, 0],\n",
    "           [1.465489372,2.362125076, 0],\n",
    "           [3.396561688,4.400293529, 0],\n",
    "           [1.38807019,1.850220317, 0],\n",
    "           [3.06407232,3.005305973, 0],\n",
    "           [7.627531214,2.759262235, 1],\n",
    "           [5.332441248,2.088626775, 1],\n",
    "           [6.922596716,1.77106367, 1],\n",
    "           [8.675418651,-0.242068655, 1],\n",
    "           [7.673756466,3.508563011, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5532f241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HIDDEN LAYER 1\n",
      "[{'params': [0.017096093895541564, 0.3173433393457825, 0.06229131507782726]}]\n",
      " \n",
      "OUTPUT LAYER\n",
      "[{'params': [0.8183682294180846, 0.2854913578958649]}, {'params': [0.5438444788696442, 0.7981150417513115]}]\n"
     ]
    }
   ],
   "source": [
    "# 1. Initialize network with weights\n",
    "\n",
    "n_hidden = 1 # number of hidden layers\n",
    "n_inputs = len(train[0][:-1]) # number of features\n",
    "n_hidden_neurons = [1, 1] # number of neurons in hidden layer\n",
    "n_outputs = 2 # number of possible outputs to be predicted\n",
    "\n",
    "def init_network(n_inputs, n_hidden, n_hidden_neurons, n_outputs):\n",
    "\n",
    "    network = []\n",
    "    \n",
    "    # number of parameters = 1 per input (features in original data) + bias = n_inputs + 1\n",
    "    # number of neurons in layer = n_hidden_neurons[i]\n",
    "    i = 0\n",
    "    for n in range(n_hidden):\n",
    "        if i == 0:\n",
    "            hidden_layer = [{'params': [np.random.rand() for n in range(n_inputs + 1)]} for n in range(n_hidden_neurons[i])]\n",
    "        else:\n",
    "            hidden_layer = [{'params': [np.random.rand() for n in range(n_hidden_neurons[i-1] + 1)]} for n in range(n_hidden_neurons[i])]\n",
    "        network.append(hidden_layer)\n",
    "        i += 1\n",
    "        \n",
    "    # number of parameters = 1 per input (neurons in previous hidden layer) + bias = n_hidden + 1\n",
    "    # number of neurons in layer = n_outputs\n",
    "    output_layer = [{'params': [np.random.rand() for n in range(n_hidden_neurons[i-1] + 1)]} for n in range(n_outputs)]\n",
    "    network.append(output_layer)\n",
    "    \n",
    "    return network\n",
    "\n",
    "def print_layers(network):\n",
    "    i = 0\n",
    "    for layer in network:\n",
    "        if i < n_hidden:\n",
    "            print(f'HIDDEN LAYER {i+1}')\n",
    "            print(layer)\n",
    "            print(' ')\n",
    "        if i == n_hidden:\n",
    "            print('OUTPUT LAYER')\n",
    "            print(layer)\n",
    "        i += 1\n",
    "        \n",
    "network = init_network(n_inputs, n_hidden, n_hidden_neurons, n_outputs)\n",
    "\n",
    "print_layers(network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5762d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activation functions\n",
    "def sigmoid(output):\n",
    "    return 1.0 / (1.0 + np.exp(-output))\n",
    "\n",
    "def ReLu(output):\n",
    "    return max(0, output)\n",
    "\n",
    "def tanh(output):\n",
    "    return (np.exp(output)-np.exp(-output))/(np.exp(output)+np.exp(-output))\n",
    "\n",
    "activation_functions = ('sigmoid', 'ReLu', 'tanh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "303d0af2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7048562110160425, 0.7661864825715318]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. Forward propagate\n",
    "\n",
    "# Calculates the output of a single neuron -> (weights * inputs) + bias\n",
    "def calc_neuron_output(params, inputs):\n",
    "    bias = params[-1]\n",
    "    output = bias\n",
    "    for i in range(len(params) - 1): # for every weight\n",
    "        output += params[i] * inputs[i]\n",
    "    return output\n",
    "\n",
    "def forward_propagate(network, inputs):\n",
    "    \n",
    "    for layer in network:\n",
    "        \n",
    "        # this list will store the activated output of each neuron to be the input of the next layer\n",
    "        # (in case the current layer is a hidden layer). Otherwise, this list will represent the outputs of the model\n",
    "        next_inputs = []\n",
    "        \n",
    "        for neuron in layer:\n",
    "            neuron_out = calc_neuron_output(neuron['params'], inputs) # linear output of neuron\n",
    "            neuron['output_activated'] = sigmoid(neuron_out) # sigmoid activation of linear output\n",
    "            next_inputs.append(neuron['output_activated'])\n",
    "            \n",
    "        inputs = next_inputs\n",
    "\n",
    "    return inputs # outputs of output layer\n",
    "\n",
    "forward_propagate(network, train[0][:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e095d180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Derivatives of activation functions\n",
    "def d_sigmoid(s):\n",
    "    return s*(1-s)\n",
    "\n",
    "def d_ReLu(r):\n",
    "    return 1 if r > 0 else 0\n",
    "\n",
    "def d_tanh(t):\n",
    "    return 1-t**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c81b581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HIDDEN LAYER 1\n",
      "[{'params': [0.017096093895541564, 0.3173433393457825, 0.06229131507782726], 'output_activated': 0.7148857802693515}]\n",
      " \n",
      "OUTPUT LAYER\n",
      "[{'params': [0.8183682294180846, 0.2854913578958649], 'output_activated': 0.7048562110160425}, {'params': [0.5438444788696442, 0.7981150417513115], 'output_activated': 0.7661864825715318}]\n"
     ]
    }
   ],
   "source": [
    "print_layers(network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e83fd4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Back propagate error\n",
    "\n",
    "# delta (error) for neuron in output layer = (y_pred-y_expected) * d_actv\n",
    "# delta (error) for neuron in hidden layers = sum(all connected weights from top layer * corresponding delta)\n",
    "\n",
    "# i is the ith layer of the network we are iterating through\n",
    "# expected_output are the expected outputs of the network (neurons in the output layer)\n",
    "##([1,0] for 0 , [0,1] for 1) (answer corresponds to the index where 1 is)\n",
    "\n",
    "def backpropagate(network, i, expected_output):\n",
    "    \n",
    "    # Base case -- backpropagation starts in output layer\n",
    "    if i == n_hidden:\n",
    "\n",
    "        for n in range(len(network[i])): # loop through each neuron in the layer i of the network (output layer)\n",
    "            neuron = network[i][n] # current neuron\n",
    "            error = neuron['output_activated'] - expected_output[n] # error for output in neuron n of output layer\n",
    "            neuron['delta'] = error * d_sigmoid(neuron['output_activated'])\n",
    "        return\n",
    "    # End of base case\n",
    "\n",
    "    errors = backpropagate(network, i + 1, expected_output)\n",
    "    \n",
    "    for n in range(len(network[i])): # loop through each neuron in the layer i of the network (hidden layer)\n",
    "        neuron = network[i][n] # current neuron\n",
    "        error = 0.0\n",
    "        for top_neuron in network[i+1]: # for each neuron in layer above\n",
    "            # (weights of top layer that the neuron output was multiplied by) * (corresponding delta)\n",
    "            error += top_neuron['params'][n] * top_neuron['delta']\n",
    "        neuron['delta'] = error * d_sigmoid(neuron['output_activated'])\n",
    "        \n",
    "    return\n",
    "            \n",
    "backpropagate(network, 0, [1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6417c4ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HIDDEN LAYER 1\n",
      "[{'params': [0.017096093895541564, 0.3173433393457825, 0.06229131507782726], 'output_activated': 0.7148857802693515, 'delta': 0.004973189296678377}]\n",
      " \n",
      "OUTPUT LAYER\n",
      "[{'params': [0.8183682294180846, 0.2854913578958649], 'output_activated': 0.7048562110160425, 'delta': -0.06139992316623163}, {'params': [0.5438444788696442, 0.7981150417513115], 'output_activated': 0.7661864825715318, 'delta': 0.13725829085095367}]\n"
     ]
    }
   ],
   "source": [
    "print_layers(network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9bbbab97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Train network\n",
    "\n",
    "def update_weights(network, row, lr):\n",
    "    for i in range(len(network)): # for every layer in the network\n",
    "        inputs = row[:-1] # take training inputs\n",
    "        if i != 0: # for all layers except the first\n",
    "            inputs = [neuron['output_activated'] for neuron in network[i-1]] # inputs are the output of the previous layer\n",
    "        for neuron in network[i]: # for every neuron in the layer\n",
    "            for j in range(len(inputs)): # for every input to the layer (every weight in the neuron)\n",
    "                neuron['params'][j] -= lr * neuron['delta'] * inputs[j] # weight update\n",
    "            neuron['params'][-1] -= lr * neuron['delta'] # bias update\n",
    "\n",
    "def train_network(network, training_data, lr, n_epochs):\n",
    "    \n",
    "    for n_epoch in range(n_epochs):\n",
    "        sse = 0.0\n",
    "        \n",
    "        for row in training_data:\n",
    "            output = forward_propagate(network, row)\n",
    "            expected = [0 for i in range(len(output))] # initialize to an array of 0s of same size as outputs\n",
    "            expected[row[-1]] = 1 # if actual output is 1, expected is [0,1], if 0 it is [1,0]\n",
    "            sse += sum([(expected[i]-output[i])**2 for i in range(len(expected))])\n",
    "            backpropagate(network, 0, expected)\n",
    "            update_weights(network, row, lr)\n",
    "        \n",
    "        if n_epoch % 50 == 0:\n",
    "            print('>epoch=%d, error=%.3f' % (n_epoch, sse)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44af0b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">epoch=0, error=5.397\n",
      ">epoch=50, error=5.083\n",
      ">epoch=100, error=2.326\n",
      ">epoch=150, error=0.656\n",
      ">epoch=200, error=0.340\n",
      ">epoch=250, error=0.223\n",
      ">epoch=300, error=0.164\n",
      ">epoch=350, error=0.129\n",
      ">epoch=400, error=0.106\n",
      ">epoch=450, error=0.090\n",
      ">epoch=500, error=0.078\n"
     ]
    }
   ],
   "source": [
    "def backprop(training_data, lr, n_epochs, n_inputs, n_hidden, n_hidden_neurons, n_outputs):\n",
    "    model = init_network(n_inputs, n_hidden, n_hidden_neurons, n_outputs)\n",
    "    train_network(model, training_data, lr, n_epochs)\n",
    "    \n",
    "    return model\n",
    "    \n",
    "lr = 0.2\n",
    "training_data = train\n",
    "n_epochs = 501\n",
    "\n",
    "model = backprop(training_data, lr, n_epochs, n_inputs, n_hidden, n_hidden_neurons, n_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "897c88a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### 5. Predict\n",
    "def predict(model, train):\n",
    "    \n",
    "    preds = [] # stores the predictions of all data points of the training data\n",
    "    \n",
    "    for row in training_data:\n",
    "        label = row[-1]\n",
    "        features = row[:-1]\n",
    "        outputs = forward_propagate(model, features)\n",
    "        pred = outputs.index(max(outputs))\n",
    "        preds.append(pred)\n",
    "    \n",
    "    return preds\n",
    "\n",
    "predict(model, train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "5ff529cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a csv file\n",
    "def load_csv(filename):\n",
    "    dataset = list()\n",
    "    with open(filename, 'r') as file:\n",
    "        csv_reader = csv.reader(file)\n",
    "        for row in csv_reader:\n",
    "            if not row:\n",
    "                continue\n",
    "            dataset.append(row)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "95689dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">epoch=0, error=118.109\n",
      ">epoch=50, error=48.906\n",
      ">epoch=100, error=45.667\n",
      ">epoch=150, error=27.902\n",
      ">epoch=200, error=23.561\n",
      ">epoch=250, error=22.193\n",
      ">epoch=300, error=21.502\n",
      ">epoch=350, error=21.101\n",
      ">epoch=400, error=20.847\n",
      ">epoch=450, error=20.677\n",
      ">epoch=500, error=20.557\n"
     ]
    }
   ],
   "source": [
    "# 6. Predict on fraud detection dataset - https://www.kaggle.com/datasets/whenamancodes/fraud-detection?resource=download\n",
    "\n",
    "ccard_data = load_csv('creditcard.csv')\n",
    "ccard_data_mod = []\n",
    "i = 0\n",
    "for row in ccard_data: # take only first 2 features and output, convert from string to float/integer\n",
    "    if i != 0:\n",
    "        new_row = row[1:3]\n",
    "        for j in range(len(new_row)):\n",
    "            new_row[j] = float(new_row[j])\n",
    "        new_row.append(int(row[30]))\n",
    "\n",
    "        ccard_data_mod.append(new_row)\n",
    "    i += 1\n",
    "\n",
    "traincc = ccard_data_mod[:8000]\n",
    "testcc = ccard_data_mod[8000:10000]\n",
    "\n",
    "lr = 0.1\n",
    "training_data = traincc\n",
    "n_epochscc = 501\n",
    "\n",
    "n_hiddencc = 1 # number of hidden layers\n",
    "n_inputscc = len(traincc[0][:-1]) # number of features\n",
    "n_hidden_neuronscc = [1,1] # number of neurons in hidden layer\n",
    "n_outputscc = 2 # number of possible outputs to be predicted\n",
    "\n",
    "modelcc = backprop(traincc, lr, n_epochscc, n_inputscc, n_hiddencc, n_hidden_neuronscc, n_outputscc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5e285659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "class ConfusionMatrix:\n",
    "    \n",
    "    def __init__(self, modelcm, data):\n",
    "        self.model = modelcm\n",
    "        self.data = data\n",
    "        self.conf_matrix = None\n",
    "        \n",
    "        # METRICS\n",
    "        self.accuracy = 0.0\n",
    "        self.precision = 0.0\n",
    "        self.recall = 0.0\n",
    "        self.fprate = 0.0\n",
    "        self.fnrate = 0.0\n",
    "        \n",
    "    def predict(self):\n",
    "    \n",
    "        preds = [] # stores the predictions of all data points of the training data\n",
    "\n",
    "        for row in self.data:\n",
    "            features = row[:-1]\n",
    "            outputs = forward_propagate(self.model, features)\n",
    "            pred = outputs.index(max(outputs))\n",
    "            preds.append(pred)\n",
    "\n",
    "        return preds\n",
    "    \n",
    "    def print_matrix(self):\n",
    "        print(self.conf_matrix)\n",
    "        print(' ')\n",
    "        \n",
    "    def print_metrics(self):\n",
    "        # Accuracy (what fraction does it get right) = (# TP + # TN) / Total\n",
    "        self.accuracy = (self.conf_matrix['TPs'] + self.conf_matrix['TNs']) / sum(self.conf_matrix.values())\n",
    "        print('ACCURACY: ', round(self.accuracy, 3))\n",
    "        print(' ')\n",
    "        \n",
    "        # Precision (when it says 1, how often is it right) = # TP / (# TP + # FP)\n",
    "        self.precision = self.conf_matrix['TPs'] / (self.conf_matrix['TPs'] + self.conf_matrix['FPs'])\n",
    "        print('PRECISION: ', round(self.precision, 3))\n",
    "        print(' ')\n",
    "        \n",
    "        # Recall (what fraction of 1s does it get right) = # TP / (# TP + # FN)\n",
    "        self.recall = self.conf_matrix['TPs'] / (self.conf_matrix['TPs'] + self.conf_matrix['FNs'])\n",
    "        print('RECALL: ', round(self.recall, 3))\n",
    "        print(' ')\n",
    "        \n",
    "        # False positive rate (what fraction of 0s are called 1s) = # FP / (# FP + # TN)\n",
    "        self.fprate = self.conf_matrix['FPs'] / (self.conf_matrix['FPs'] + self.conf_matrix['TNs'])\n",
    "        print('FALSE POSITIVE RATE: ', round(self.fprate, 3))\n",
    "        print(' ')\n",
    "        \n",
    "        # False negative rate (what fraction of 1s are called 0s) = # FN / (# TP + # FN)\n",
    "        self.fnrate = self.conf_matrix['FNs'] / (self.conf_matrix['TPs'] + self.conf_matrix['FNs'])\n",
    "        print('FALSE NEGATIVE RATE: ', round(self.fnrate, 3))\n",
    "    \n",
    "    \n",
    "    def plot_matrix(self):\n",
    "        matrix_arr = [[self.conf_matrix['TNs'], self.conf_matrix['FPs']], [self.conf_matrix['FNs'], self.conf_matrix['TPs']]]\n",
    "        plt.imshow(matrix_arr, cmap = 'coolwarm', alpha = 0.5)\n",
    "        plt.xticks(np.arange(0, 2), ['0', '1'])\n",
    "        plt.yticks(np.arange(0, 2), ['0', '1'])\n",
    "        \n",
    "        plt.text(-0.1, 0, matrix_arr[0][0], fontsize = 14) # TNs\n",
    "        plt.text(0.95, 0, matrix_arr[0][1], fontsize = 14) # FPs\n",
    "        plt.text(-0.1, 1, matrix_arr[1][0], fontsize = 14) # FNs\n",
    "        plt.text(0.95, 1, matrix_arr[1][1], fontsize = 14) # TPs\n",
    "\n",
    "        plt.xlabel('Predictions', fontsize=18)\n",
    "        plt.ylabel('Actuals', fontsize=18)\n",
    "        plt.title('Confusion Matrix', fontsize=18)\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "    def fit(self):\n",
    "        self.conf_matrix = {'TPs': 0, 'TNs': 0, 'FPs': 0, 'FNs': 0}\n",
    "        \n",
    "        preds = self.predict()\n",
    "        \n",
    "        for i in range(len(preds)):\n",
    "            label = self.data[i][-1]\n",
    "            pred = preds[i]\n",
    "            if label == 1 and pred == 1: # truly predicted positive\n",
    "                self.conf_matrix['TPs'] += 1\n",
    "            elif label == 0 and pred == 1: # falsely predicted positive\n",
    "                self.conf_matrix['FPs'] += 1\n",
    "            elif label == 1 and pred == 0: # falsely predicted negative\n",
    "                self.conf_matrix['FNs'] += 1\n",
    "            elif label == 0 and pred == 0: # truly predicted negative\n",
    "                self.conf_matrix['TNs'] += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5836ea67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY:  0.996\n",
      " \n",
      "PRECISION:  0.625\n",
      " \n",
      "RECALL:  0.769\n",
      " \n",
      "FALSE POSITIVE RATE:  0.003\n",
      " \n",
      "FALSE NEGATIVE RATE:  0.231\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cc_cm = ConfusionMatrix(modelcc, testcc)\n",
    "cc_cm.fit()\n",
    "cc_cm.print_metrics()\n",
    "cc_cm.plot_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "66034a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Predict on titanic dataset - https://www.kaggle.com/competitions/titanic/data\n",
    "titanic_train = load_csv('titanic_train.csv')\n",
    "\n",
    "def modify_titanic(titanic_data, is_train = True):\n",
    "    # take max and min of variables to be normalized\n",
    "    age_min = 100\n",
    "    age_max = 0\n",
    "    sibsp_min = 100\n",
    "    sibsp_max = 0\n",
    "    parch_min = 100\n",
    "    parch_max = 0\n",
    "    fare_min = 100.0\n",
    "    fare_max = 0.0\n",
    "    \n",
    "    # Test set indexes\n",
    "    gender_ind = 3\n",
    "    age_ind = 4\n",
    "    sibsp_ind = 5\n",
    "    parch_ind = 6\n",
    "    fare_ind = 8\n",
    "    \n",
    "    # Adjust for train set (which includes 'Survived' label, hence the += 1)\n",
    "    if is_train:\n",
    "        gender_ind += 1\n",
    "        age_ind += 1\n",
    "        sibsp_ind += 1\n",
    "        parch_ind += 1\n",
    "        fare_ind += 1\n",
    "\n",
    "    j = 0\n",
    "    for row in titanic_data:\n",
    "        if j != 0:\n",
    "            age = int(row[age_ind]) if row[age_ind].isdigit() else age_min\n",
    "            if age < age_min:\n",
    "                age_min = age\n",
    "            if age > age_max:\n",
    "                age_max = age\n",
    "\n",
    "            sibsp = int(row[sibsp_ind]) if row[sibsp_ind].isdigit() else sibsp_min\n",
    "            if sibsp < sibsp_min:\n",
    "                sibsp_min = sibsp\n",
    "            if sibsp > sibsp_max:\n",
    "                sibsp_max = sibsp\n",
    "\n",
    "            parch = int(row[parch_ind]) if row[parch_ind].isdigit() else parch_min\n",
    "            if parch < parch_min:\n",
    "                parch_min = parch\n",
    "            if parch > parch_max:\n",
    "                parch_max = parch\n",
    "\n",
    "            fare = float(row[fare_ind]) if row[fare_ind].isdigit() else fare_min\n",
    "            if fare < fare_min:\n",
    "                fare_min = fare\n",
    "            if fare > fare_max:\n",
    "                fare_max = fare\n",
    "        j += 1\n",
    "    \n",
    "    titanic_mod = []\n",
    "    invalids = [0] # indexes of invalid rows\n",
    "\n",
    "    for i in range(len(titanic_data)): # take only first 2 features and output, convert from string to float/integer\n",
    "\n",
    "        if i != 0:\n",
    "\n",
    "            row = titanic_data[i]\n",
    "            new_row = []\n",
    "\n",
    "            gender = 1 if row[gender_ind] == 'male' else 0 # ind = 3 (test), 4 (train)\n",
    "            new_row.append(gender)\n",
    "\n",
    "            # scale 'Age' variable (row[5]) to [0,1] range and append to new_row\n",
    "            if row[age_ind].isdigit(): # ind = 4 (test), 5 (train)\n",
    "                age = int(row[age_ind])\n",
    "                age_scaled = (age - age_min) / (age_max - age_min)\n",
    "                new_row.append(age_scaled)\n",
    "\n",
    "            # scale 'SibSp' variable (row[6]) and append to new_row\n",
    "            if row[sibsp_ind].isdigit(): # ind = 5 (test), 6 (train)\n",
    "                sibsp = int(row[sibsp_ind])\n",
    "                sibsp_scaled = (sibsp - sibsp_min) / (sibsp_max - sibsp_min)\n",
    "                new_row.append(sibsp_scaled)\n",
    "\n",
    "            # scale 'Parch' variable (row[7]) and append to new_row\n",
    "            if row[parch_ind].isdigit(): # ind = 6 (test), 7 (train)\n",
    "                parch = int(row[parch_ind])\n",
    "                parch_scaled = (parch - parch_min) / (parch_max - parch_min)\n",
    "                new_row.append(parch_scaled)\n",
    "\n",
    "            # scale 'Fare' variable (row[9]) and append to new_row\n",
    "            if row[fare_ind].replace('.','',1).isdigit(): # ind = 8 (test), 9 (train)\n",
    "                fare = float(row[fare_ind])\n",
    "                fare_scaled = (fare - fare_min) / (fare_max - fare_min)\n",
    "                new_row.append(fare_scaled)\n",
    "\n",
    "            # append label ('Survived') (row[1]) to new_row\n",
    "            if is_train:\n",
    "                new_row.append(int(row[1]))\n",
    "\n",
    "            if row[age_ind].isdigit() and row[sibsp_ind].isdigit() and row[parch_ind].isdigit() and row[fare_ind].replace('.','',1).isdigit():\n",
    "                titanic_mod.append(new_row)\n",
    "            else:\n",
    "                invalids.append(i)\n",
    "                \n",
    "    return (titanic_mod, invalids)\n",
    "\n",
    "titanic_train_mod = modify_titanic(titanic_train)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d4e387df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">epoch=0, error=363.822\n",
      ">epoch=50, error=216.604\n",
      ">epoch=100, error=210.771\n",
      ">epoch=150, error=204.431\n",
      ">epoch=200, error=200.632\n",
      ">epoch=250, error=198.981\n",
      ">epoch=300, error=197.669\n",
      ">epoch=350, error=196.519\n",
      ">epoch=400, error=195.472\n",
      ">epoch=450, error=194.395\n",
      ">epoch=500, error=193.192\n"
     ]
    }
   ],
   "source": [
    "lr = 0.2\n",
    "training_data = titanic_train_mod\n",
    "n_epochs_titanic = 501\n",
    "\n",
    "n_hidden_titanic = 1 # number of hidden layers\n",
    "n_inputs_titanic = len(titanic_train_mod[0][:-1]) # number of features\n",
    "n_hidden_neurons_titanic = [5,1] # number of neurons in hidden layer\n",
    "n_outputs_titanic = 2 # number of possible outputs to be predicted\n",
    "\n",
    "model_titanic = backprop(titanic_train_mod, lr, n_epochs_titanic, n_inputs_titanic, n_hidden_titanic, n_hidden_neurons_titanic, n_outputs_titanic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "79365c69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY:  0.813\n",
      " \n",
      "PRECISION:  0.795\n",
      " \n",
      "RECALL:  0.73\n",
      " \n",
      "FALSE POSITIVE RATE:  0.13\n",
      " \n",
      "FALSE NEGATIVE RATE:  0.27\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "conf_matrix_titanic = ConfusionMatrix(model_titanic, titanic_train_mod)\n",
    "conf_matrix_titanic.fit()\n",
    "conf_matrix_titanic.print_metrics()\n",
    "conf_matrix_titanic.plot_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "a0a1c4cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1,\n",
       " 11,\n",
       " 23,\n",
       " 28,\n",
       " 30,\n",
       " 34,\n",
       " 36,\n",
       " 37,\n",
       " 40,\n",
       " 42,\n",
       " 48,\n",
       " 55,\n",
       " 59,\n",
       " 66,\n",
       " 74,\n",
       " 76,\n",
       " 77,\n",
       " 84,\n",
       " 85,\n",
       " 86,\n",
       " 89,\n",
       " 92,\n",
       " 94,\n",
       " 103,\n",
       " 108,\n",
       " 109,\n",
       " 110,\n",
       " 112,\n",
       " 114,\n",
       " 117,\n",
       " 122,\n",
       " 125,\n",
       " 128,\n",
       " 133,\n",
       " 134,\n",
       " 137,\n",
       " 147,\n",
       " 149,\n",
       " 152,\n",
       " 153,\n",
       " 161,\n",
       " 164,\n",
       " 169,\n",
       " 171,\n",
       " 174,\n",
       " 184,\n",
       " 189,\n",
       " 192,\n",
       " 193,\n",
       " 200,\n",
       " 201,\n",
       " 202,\n",
       " 206,\n",
       " 212,\n",
       " 217,\n",
       " 220,\n",
       " 226,\n",
       " 228,\n",
       " 229,\n",
       " 234,\n",
       " 244,\n",
       " 245,\n",
       " 250,\n",
       " 251,\n",
       " 255,\n",
       " 256,\n",
       " 257,\n",
       " 261,\n",
       " 266,\n",
       " 267,\n",
       " 268,\n",
       " 269,\n",
       " 272,\n",
       " 274,\n",
       " 275,\n",
       " 282,\n",
       " 283,\n",
       " 287,\n",
       " 289,\n",
       " 290,\n",
       " 291,\n",
       " 293,\n",
       " 298,\n",
       " 302,\n",
       " 305,\n",
       " 308,\n",
       " 313,\n",
       " 333,\n",
       " 340,\n",
       " 343,\n",
       " 345,\n",
       " 355,\n",
       " 358,\n",
       " 359,\n",
       " 361,\n",
       " 366,\n",
       " 367,\n",
       " 381,\n",
       " 383,\n",
       " 385,\n",
       " 409,\n",
       " 411,\n",
       " 414,\n",
       " 416,\n",
       " 417,\n",
       " 418]"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Kaggle submission - .csv file with columns 'PassengerId', 'Survived'\n",
    "titanic_test = load_csv('titanic_test.csv')\n",
    "titanic_test_mod, test_invalids = modify_titanic(titanic_test, is_train = False)\n",
    "\n",
    "test_invalids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "d3471694",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_submission(model, data, data_mod, invalids):\n",
    "    \n",
    "    submission = []\n",
    "    mod_index = 0\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        if i != 0:\n",
    "            if i in invalids:\n",
    "                pred = random.choice([0,1])\n",
    "            else:\n",
    "                features = data_mod[mod_index]\n",
    "                outputs = forward_propagate(model, features)\n",
    "                pred = outputs.index(max(outputs))\n",
    "                mod_index += 1\n",
    "            submission.append([i+891, pred])\n",
    "        \n",
    "    return submission\n",
    "\n",
    "# if index of row in titanic_test in invalids, predict randomly 0 or 1\n",
    "titanic_submission = predict_submission(model_titanic, titanic_test, titanic_test_mod, test_invalids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "4255f253",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[892, 1],\n",
       " [893, 0],\n",
       " [894, 0],\n",
       " [895, 0],\n",
       " [896, 0],\n",
       " [897, 0],\n",
       " [898, 1],\n",
       " [899, 0],\n",
       " [900, 1],\n",
       " [901, 0],\n",
       " [902, 1],\n",
       " [903, 0],\n",
       " [904, 1],\n",
       " [905, 0],\n",
       " [906, 1],\n",
       " [907, 1],\n",
       " [908, 0],\n",
       " [909, 0],\n",
       " [910, 0],\n",
       " [911, 1],\n",
       " [912, 0],\n",
       " [913, 0],\n",
       " [914, 0],\n",
       " [915, 1],\n",
       " [916, 1],\n",
       " [917, 0],\n",
       " [918, 1],\n",
       " [919, 0],\n",
       " [920, 0],\n",
       " [921, 1],\n",
       " [922, 0],\n",
       " [923, 0],\n",
       " [924, 1],\n",
       " [925, 1],\n",
       " [926, 1],\n",
       " [927, 1],\n",
       " [928, 1],\n",
       " [929, 1],\n",
       " [930, 0],\n",
       " [931, 1],\n",
       " [932, 0],\n",
       " [933, 1],\n",
       " [934, 0],\n",
       " [935, 1],\n",
       " [936, 1],\n",
       " [937, 0],\n",
       " [938, 0],\n",
       " [939, 0],\n",
       " [940, 1],\n",
       " [941, 1],\n",
       " [942, 1],\n",
       " [943, 0],\n",
       " [944, 0],\n",
       " [945, 1],\n",
       " [946, 1],\n",
       " [947, 0],\n",
       " [948, 0],\n",
       " [949, 0],\n",
       " [950, 0],\n",
       " [951, 1],\n",
       " [952, 0],\n",
       " [953, 0],\n",
       " [954, 0],\n",
       " [955, 1],\n",
       " [956, 0],\n",
       " [957, 0],\n",
       " [958, 1],\n",
       " [959, 0],\n",
       " [960, 0],\n",
       " [961, 1],\n",
       " [962, 1],\n",
       " [963, 0],\n",
       " [964, 1],\n",
       " [965, 0],\n",
       " [966, 1],\n",
       " [967, 1],\n",
       " [968, 1],\n",
       " [969, 0],\n",
       " [970, 0],\n",
       " [971, 1],\n",
       " [972, 0],\n",
       " [973, 0],\n",
       " [974, 0],\n",
       " [975, 0],\n",
       " [976, 1],\n",
       " [977, 0],\n",
       " [978, 1],\n",
       " [979, 1],\n",
       " [980, 0],\n",
       " [981, 0],\n",
       " [982, 1],\n",
       " [983, 0],\n",
       " [984, 1],\n",
       " [985, 0],\n",
       " [986, 0],\n",
       " [987, 0],\n",
       " [988, 1],\n",
       " [989, 0],\n",
       " [990, 1],\n",
       " [991, 0],\n",
       " [992, 1],\n",
       " [993, 0],\n",
       " [994, 0],\n",
       " [995, 0],\n",
       " [996, 0],\n",
       " [997, 0],\n",
       " [998, 0],\n",
       " [999, 1],\n",
       " [1000, 1],\n",
       " [1001, 0],\n",
       " [1002, 0],\n",
       " [1003, 1],\n",
       " [1004, 1],\n",
       " [1005, 1],\n",
       " [1006, 1],\n",
       " [1007, 0],\n",
       " [1008, 1],\n",
       " [1009, 1],\n",
       " [1010, 1],\n",
       " [1011, 1],\n",
       " [1012, 1],\n",
       " [1013, 1],\n",
       " [1014, 1],\n",
       " [1015, 0],\n",
       " [1016, 0],\n",
       " [1017, 1],\n",
       " [1018, 0],\n",
       " [1019, 0],\n",
       " [1020, 0],\n",
       " [1021, 0],\n",
       " [1022, 0],\n",
       " [1023, 0],\n",
       " [1024, 1],\n",
       " [1025, 0],\n",
       " [1026, 0],\n",
       " [1027, 0],\n",
       " [1028, 0],\n",
       " [1029, 0],\n",
       " [1030, 1],\n",
       " [1031, 0],\n",
       " [1032, 0],\n",
       " [1033, 1],\n",
       " [1034, 0],\n",
       " [1035, 0],\n",
       " [1036, 0],\n",
       " [1037, 0],\n",
       " [1038, 1],\n",
       " [1039, 0],\n",
       " [1040, 1],\n",
       " [1041, 0],\n",
       " [1042, 1],\n",
       " [1043, 1],\n",
       " [1044, 1],\n",
       " [1045, 1],\n",
       " [1046, 0],\n",
       " [1047, 0],\n",
       " [1048, 1],\n",
       " [1049, 1],\n",
       " [1050, 0],\n",
       " [1051, 1],\n",
       " [1052, 1],\n",
       " [1053, 0],\n",
       " [1054, 1],\n",
       " [1055, 0],\n",
       " [1056, 0],\n",
       " [1057, 1],\n",
       " [1058, 1],\n",
       " [1059, 0],\n",
       " [1060, 0],\n",
       " [1061, 1],\n",
       " [1062, 1],\n",
       " [1063, 0],\n",
       " [1064, 0],\n",
       " [1065, 1],\n",
       " [1066, 0],\n",
       " [1067, 1],\n",
       " [1068, 1],\n",
       " [1069, 0],\n",
       " [1070, 1],\n",
       " [1071, 1],\n",
       " [1072, 0],\n",
       " [1073, 1],\n",
       " [1074, 1],\n",
       " [1075, 1],\n",
       " [1076, 1],\n",
       " [1077, 0],\n",
       " [1078, 1],\n",
       " [1079, 0],\n",
       " [1080, 1],\n",
       " [1081, 0],\n",
       " [1082, 0],\n",
       " [1083, 1],\n",
       " [1084, 0],\n",
       " [1085, 0],\n",
       " [1086, 1],\n",
       " [1087, 0],\n",
       " [1088, 1],\n",
       " [1089, 1],\n",
       " [1090, 0],\n",
       " [1091, 1],\n",
       " [1092, 0],\n",
       " [1093, 0],\n",
       " [1094, 0],\n",
       " [1095, 1],\n",
       " [1096, 0],\n",
       " [1097, 0],\n",
       " [1098, 1],\n",
       " [1099, 0],\n",
       " [1100, 1],\n",
       " [1101, 0],\n",
       " [1102, 0],\n",
       " [1103, 0],\n",
       " [1104, 1],\n",
       " [1105, 1],\n",
       " [1106, 0],\n",
       " [1107, 1],\n",
       " [1108, 1],\n",
       " [1109, 0],\n",
       " [1110, 1],\n",
       " [1111, 0],\n",
       " [1112, 1],\n",
       " [1113, 0],\n",
       " [1114, 1],\n",
       " [1115, 0],\n",
       " [1116, 1],\n",
       " [1117, 1],\n",
       " [1118, 0],\n",
       " [1119, 1],\n",
       " [1120, 0],\n",
       " [1121, 0],\n",
       " [1122, 1],\n",
       " [1123, 1],\n",
       " [1124, 0],\n",
       " [1125, 1],\n",
       " [1126, 1],\n",
       " [1127, 0],\n",
       " [1128, 0],\n",
       " [1129, 0],\n",
       " [1130, 0],\n",
       " [1131, 1],\n",
       " [1132, 1],\n",
       " [1133, 1],\n",
       " [1134, 0],\n",
       " [1135, 1],\n",
       " [1136, 1],\n",
       " [1137, 0],\n",
       " [1138, 1],\n",
       " [1139, 0],\n",
       " [1140, 1],\n",
       " [1141, 0],\n",
       " [1142, 0],\n",
       " [1143, 0],\n",
       " [1144, 0],\n",
       " [1145, 0],\n",
       " [1146, 1],\n",
       " [1147, 0],\n",
       " [1148, 0],\n",
       " [1149, 0],\n",
       " [1150, 1],\n",
       " [1151, 0],\n",
       " [1152, 1],\n",
       " [1153, 0],\n",
       " [1154, 1],\n",
       " [1155, 1],\n",
       " [1156, 0],\n",
       " [1157, 1],\n",
       " [1158, 0],\n",
       " [1159, 0],\n",
       " [1160, 1],\n",
       " [1161, 0],\n",
       " [1162, 1],\n",
       " [1163, 0],\n",
       " [1164, 1],\n",
       " [1165, 0],\n",
       " [1166, 0],\n",
       " [1167, 1],\n",
       " [1168, 0],\n",
       " [1169, 0],\n",
       " [1170, 0],\n",
       " [1171, 0],\n",
       " [1172, 1],\n",
       " [1173, 0],\n",
       " [1174, 0],\n",
       " [1175, 1],\n",
       " [1176, 1],\n",
       " [1177, 0],\n",
       " [1178, 1],\n",
       " [1179, 1],\n",
       " [1180, 0],\n",
       " [1181, 1],\n",
       " [1182, 1],\n",
       " [1183, 1],\n",
       " [1184, 0],\n",
       " [1185, 0],\n",
       " [1186, 0],\n",
       " [1187, 0],\n",
       " [1188, 1],\n",
       " [1189, 1],\n",
       " [1190, 1],\n",
       " [1191, 0],\n",
       " [1192, 0],\n",
       " [1193, 1],\n",
       " [1194, 0],\n",
       " [1195, 0],\n",
       " [1196, 0],\n",
       " [1197, 1],\n",
       " [1198, 0],\n",
       " [1199, 1],\n",
       " [1200, 0],\n",
       " [1201, 0],\n",
       " [1202, 0],\n",
       " [1203, 0],\n",
       " [1204, 1],\n",
       " [1205, 1],\n",
       " [1206, 1],\n",
       " [1207, 1],\n",
       " [1208, 0],\n",
       " [1209, 0],\n",
       " [1210, 0],\n",
       " [1211, 0],\n",
       " [1212, 0],\n",
       " [1213, 0],\n",
       " [1214, 0],\n",
       " [1215, 0],\n",
       " [1216, 1],\n",
       " [1217, 0],\n",
       " [1218, 1],\n",
       " [1219, 1],\n",
       " [1220, 0],\n",
       " [1221, 0],\n",
       " [1222, 1],\n",
       " [1223, 0],\n",
       " [1224, 1],\n",
       " [1225, 1],\n",
       " [1226, 0],\n",
       " [1227, 0],\n",
       " [1228, 0],\n",
       " [1229, 0],\n",
       " [1230, 0],\n",
       " [1231, 0],\n",
       " [1232, 0],\n",
       " [1233, 0],\n",
       " [1234, 0],\n",
       " [1235, 1],\n",
       " [1236, 0],\n",
       " [1237, 1],\n",
       " [1238, 0],\n",
       " [1239, 1],\n",
       " [1240, 0],\n",
       " [1241, 1],\n",
       " [1242, 1],\n",
       " [1243, 0],\n",
       " [1244, 1],\n",
       " [1245, 0],\n",
       " [1246, 1],\n",
       " [1247, 0],\n",
       " [1248, 1],\n",
       " [1249, 0],\n",
       " [1250, 1],\n",
       " [1251, 1],\n",
       " [1252, 0],\n",
       " [1253, 1],\n",
       " [1254, 1],\n",
       " [1255, 0],\n",
       " [1256, 1],\n",
       " [1257, 1],\n",
       " [1258, 1],\n",
       " [1259, 1],\n",
       " [1260, 1],\n",
       " [1261, 0],\n",
       " [1262, 0],\n",
       " [1263, 1],\n",
       " [1264, 0],\n",
       " [1265, 0],\n",
       " [1266, 1],\n",
       " [1267, 1],\n",
       " [1268, 0],\n",
       " [1269, 0],\n",
       " [1270, 0],\n",
       " [1271, 0],\n",
       " [1272, 0],\n",
       " [1273, 0],\n",
       " [1274, 1],\n",
       " [1275, 1],\n",
       " [1276, 0],\n",
       " [1277, 1],\n",
       " [1278, 0],\n",
       " [1279, 0],\n",
       " [1280, 0],\n",
       " [1281, 0],\n",
       " [1282, 1],\n",
       " [1283, 1],\n",
       " [1284, 1],\n",
       " [1285, 0],\n",
       " [1286, 0],\n",
       " [1287, 1],\n",
       " [1288, 0],\n",
       " [1289, 1],\n",
       " [1290, 0],\n",
       " [1291, 0],\n",
       " [1292, 1],\n",
       " [1293, 0],\n",
       " [1294, 1],\n",
       " [1295, 1],\n",
       " [1296, 0],\n",
       " [1297, 0],\n",
       " [1298, 0],\n",
       " [1299, 0],\n",
       " [1300, 1],\n",
       " [1301, 1],\n",
       " [1302, 0],\n",
       " [1303, 1],\n",
       " [1304, 1],\n",
       " [1305, 1],\n",
       " [1306, 1],\n",
       " [1307, 0],\n",
       " [1308, 0],\n",
       " [1309, 0]]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "26844529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The content of the csv file is:\n",
      "PassengerId,Survived\n",
      "892,1\n",
      "893,0\n",
      "894,0\n",
      "895,0\n",
      "896,0\n",
      "897,0\n",
      "898,1\n",
      "899,0\n",
      "900,1\n",
      "901,0\n",
      "902,1\n",
      "903,0\n",
      "904,1\n",
      "905,0\n",
      "906,1\n",
      "907,1\n",
      "908,0\n",
      "909,0\n",
      "910,0\n",
      "911,1\n",
      "912,0\n",
      "913,0\n",
      "914,0\n",
      "915,1\n",
      "916,1\n",
      "917,0\n",
      "918,1\n",
      "919,0\n",
      "920,0\n",
      "921,1\n",
      "922,0\n",
      "923,0\n",
      "924,1\n",
      "925,1\n",
      "926,1\n",
      "927,1\n",
      "928,1\n",
      "929,1\n",
      "930,0\n",
      "931,1\n",
      "932,0\n",
      "933,1\n",
      "934,0\n",
      "935,1\n",
      "936,1\n",
      "937,0\n",
      "938,0\n",
      "939,0\n",
      "940,1\n",
      "941,1\n",
      "942,1\n",
      "943,0\n",
      "944,0\n",
      "945,1\n",
      "946,1\n",
      "947,0\n",
      "948,0\n",
      "949,0\n",
      "950,0\n",
      "951,1\n",
      "952,0\n",
      "953,0\n",
      "954,0\n",
      "955,1\n",
      "956,0\n",
      "957,0\n",
      "958,1\n",
      "959,0\n",
      "960,0\n",
      "961,1\n",
      "962,1\n",
      "963,0\n",
      "964,1\n",
      "965,0\n",
      "966,1\n",
      "967,1\n",
      "968,1\n",
      "969,0\n",
      "970,0\n",
      "971,1\n",
      "972,0\n",
      "973,0\n",
      "974,0\n",
      "975,0\n",
      "976,1\n",
      "977,0\n",
      "978,1\n",
      "979,1\n",
      "980,0\n",
      "981,0\n",
      "982,1\n",
      "983,0\n",
      "984,1\n",
      "985,0\n",
      "986,0\n",
      "987,0\n",
      "988,1\n",
      "989,0\n",
      "990,1\n",
      "991,0\n",
      "992,1\n",
      "993,0\n",
      "994,0\n",
      "995,0\n",
      "996,0\n",
      "997,0\n",
      "998,0\n",
      "999,1\n",
      "1000,1\n",
      "1001,0\n",
      "1002,0\n",
      "1003,1\n",
      "1004,1\n",
      "1005,1\n",
      "1006,1\n",
      "1007,0\n",
      "1008,1\n",
      "1009,1\n",
      "1010,1\n",
      "1011,1\n",
      "1012,1\n",
      "1013,1\n",
      "1014,1\n",
      "1015,0\n",
      "1016,0\n",
      "1017,1\n",
      "1018,0\n",
      "1019,0\n",
      "1020,0\n",
      "1021,0\n",
      "1022,0\n",
      "1023,0\n",
      "1024,1\n",
      "1025,0\n",
      "1026,0\n",
      "1027,0\n",
      "1028,0\n",
      "1029,0\n",
      "1030,1\n",
      "1031,0\n",
      "1032,0\n",
      "1033,1\n",
      "1034,0\n",
      "1035,0\n",
      "1036,0\n",
      "1037,0\n",
      "1038,1\n",
      "1039,0\n",
      "1040,1\n",
      "1041,0\n",
      "1042,1\n",
      "1043,1\n",
      "1044,1\n",
      "1045,1\n",
      "1046,0\n",
      "1047,0\n",
      "1048,1\n",
      "1049,1\n",
      "1050,0\n",
      "1051,1\n",
      "1052,1\n",
      "1053,0\n",
      "1054,1\n",
      "1055,0\n",
      "1056,0\n",
      "1057,1\n",
      "1058,1\n",
      "1059,0\n",
      "1060,0\n",
      "1061,1\n",
      "1062,1\n",
      "1063,0\n",
      "1064,0\n",
      "1065,1\n",
      "1066,0\n",
      "1067,1\n",
      "1068,1\n",
      "1069,0\n",
      "1070,1\n",
      "1071,1\n",
      "1072,0\n",
      "1073,1\n",
      "1074,1\n",
      "1075,1\n",
      "1076,1\n",
      "1077,0\n",
      "1078,1\n",
      "1079,0\n",
      "1080,1\n",
      "1081,0\n",
      "1082,0\n",
      "1083,1\n",
      "1084,0\n",
      "1085,0\n",
      "1086,1\n",
      "1087,0\n",
      "1088,1\n",
      "1089,1\n",
      "1090,0\n",
      "1091,1\n",
      "1092,0\n",
      "1093,0\n",
      "1094,0\n",
      "1095,1\n",
      "1096,0\n",
      "1097,0\n",
      "1098,1\n",
      "1099,0\n",
      "1100,1\n",
      "1101,0\n",
      "1102,0\n",
      "1103,0\n",
      "1104,1\n",
      "1105,1\n",
      "1106,0\n",
      "1107,1\n",
      "1108,1\n",
      "1109,0\n",
      "1110,1\n",
      "1111,0\n",
      "1112,1\n",
      "1113,0\n",
      "1114,1\n",
      "1115,0\n",
      "1116,1\n",
      "1117,1\n",
      "1118,0\n",
      "1119,1\n",
      "1120,0\n",
      "1121,0\n",
      "1122,1\n",
      "1123,1\n",
      "1124,0\n",
      "1125,1\n",
      "1126,1\n",
      "1127,0\n",
      "1128,0\n",
      "1129,0\n",
      "1130,0\n",
      "1131,1\n",
      "1132,1\n",
      "1133,1\n",
      "1134,0\n",
      "1135,1\n",
      "1136,1\n",
      "1137,0\n",
      "1138,1\n",
      "1139,0\n",
      "1140,1\n",
      "1141,0\n",
      "1142,0\n",
      "1143,0\n",
      "1144,0\n",
      "1145,0\n",
      "1146,1\n",
      "1147,0\n",
      "1148,0\n",
      "1149,0\n",
      "1150,1\n",
      "1151,0\n",
      "1152,1\n",
      "1153,0\n",
      "1154,1\n",
      "1155,1\n",
      "1156,0\n",
      "1157,1\n",
      "1158,0\n",
      "1159,0\n",
      "1160,1\n",
      "1161,0\n",
      "1162,1\n",
      "1163,0\n",
      "1164,1\n",
      "1165,0\n",
      "1166,0\n",
      "1167,1\n",
      "1168,0\n",
      "1169,0\n",
      "1170,0\n",
      "1171,0\n",
      "1172,1\n",
      "1173,0\n",
      "1174,0\n",
      "1175,1\n",
      "1176,1\n",
      "1177,0\n",
      "1178,1\n",
      "1179,1\n",
      "1180,0\n",
      "1181,1\n",
      "1182,1\n",
      "1183,1\n",
      "1184,0\n",
      "1185,0\n",
      "1186,0\n",
      "1187,0\n",
      "1188,1\n",
      "1189,1\n",
      "1190,1\n",
      "1191,0\n",
      "1192,0\n",
      "1193,1\n",
      "1194,0\n",
      "1195,0\n",
      "1196,0\n",
      "1197,1\n",
      "1198,0\n",
      "1199,1\n",
      "1200,0\n",
      "1201,0\n",
      "1202,0\n",
      "1203,0\n",
      "1204,1\n",
      "1205,1\n",
      "1206,1\n",
      "1207,1\n",
      "1208,0\n",
      "1209,0\n",
      "1210,0\n",
      "1211,0\n",
      "1212,0\n",
      "1213,0\n",
      "1214,0\n",
      "1215,0\n",
      "1216,1\n",
      "1217,0\n",
      "1218,1\n",
      "1219,1\n",
      "1220,0\n",
      "1221,0\n",
      "1222,1\n",
      "1223,0\n",
      "1224,1\n",
      "1225,1\n",
      "1226,0\n",
      "1227,0\n",
      "1228,0\n",
      "1229,0\n",
      "1230,0\n",
      "1231,0\n",
      "1232,0\n",
      "1233,0\n",
      "1234,0\n",
      "1235,1\n",
      "1236,0\n",
      "1237,1\n",
      "1238,0\n",
      "1239,1\n",
      "1240,0\n",
      "1241,1\n",
      "1242,1\n",
      "1243,0\n",
      "1244,1\n",
      "1245,0\n",
      "1246,1\n",
      "1247,0\n",
      "1248,1\n",
      "1249,0\n",
      "1250,1\n",
      "1251,1\n",
      "1252,0\n",
      "1253,1\n",
      "1254,1\n",
      "1255,0\n",
      "1256,1\n",
      "1257,1\n",
      "1258,1\n",
      "1259,1\n",
      "1260,1\n",
      "1261,0\n",
      "1262,0\n",
      "1263,1\n",
      "1264,0\n",
      "1265,0\n",
      "1266,1\n",
      "1267,1\n",
      "1268,0\n",
      "1269,0\n",
      "1270,0\n",
      "1271,0\n",
      "1272,0\n",
      "1273,0\n",
      "1274,1\n",
      "1275,1\n",
      "1276,0\n",
      "1277,1\n",
      "1278,0\n",
      "1279,0\n",
      "1280,0\n",
      "1281,0\n",
      "1282,1\n",
      "1283,1\n",
      "1284,1\n",
      "1285,0\n",
      "1286,0\n",
      "1287,1\n",
      "1288,0\n",
      "1289,1\n",
      "1290,0\n",
      "1291,0\n",
      "1292,1\n",
      "1293,0\n",
      "1294,1\n",
      "1295,1\n",
      "1296,0\n",
      "1297,0\n",
      "1298,0\n",
      "1299,0\n",
      "1300,1\n",
      "1301,1\n",
      "1302,0\n",
      "1303,1\n",
      "1304,1\n",
      "1305,1\n",
      "1306,1\n",
      "1307,0\n",
      "1308,0\n",
      "1309,0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Kaggle submission - .csv file with columns 'PassengerId', 'Survived'\n",
    "myFile = open('titanic_submission1.csv', 'w')\n",
    "writer = csv.writer(myFile)\n",
    "writer.writerow(['PassengerId', 'Survived'])\n",
    "for data_list in titanic_submission:\n",
    "    writer.writerow(data_list)\n",
    "myFile.close()\n",
    "myFile = open('titanic_submission1.csv', 'r')\n",
    "print(\"The content of the csv file is:\")\n",
    "print(myFile.read())\n",
    "myFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "457adc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_submission_test = load_csv('titanic_submission1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "725010ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['PassengerId', 'Survived'],\n",
       " ['892', '1'],\n",
       " ['893', '0'],\n",
       " ['894', '0'],\n",
       " ['895', '0'],\n",
       " ['896', '0'],\n",
       " ['897', '0'],\n",
       " ['898', '1'],\n",
       " ['899', '0'],\n",
       " ['900', '1'],\n",
       " ['901', '0'],\n",
       " ['902', '1'],\n",
       " ['903', '0'],\n",
       " ['904', '1'],\n",
       " ['905', '0'],\n",
       " ['906', '1'],\n",
       " ['907', '1'],\n",
       " ['908', '0'],\n",
       " ['909', '0'],\n",
       " ['910', '0'],\n",
       " ['911', '1'],\n",
       " ['912', '0'],\n",
       " ['913', '0'],\n",
       " ['914', '0'],\n",
       " ['915', '1'],\n",
       " ['916', '1'],\n",
       " ['917', '0'],\n",
       " ['918', '1'],\n",
       " ['919', '0'],\n",
       " ['920', '0'],\n",
       " ['921', '1'],\n",
       " ['922', '0'],\n",
       " ['923', '0'],\n",
       " ['924', '1'],\n",
       " ['925', '1'],\n",
       " ['926', '1'],\n",
       " ['927', '1'],\n",
       " ['928', '1'],\n",
       " ['929', '1'],\n",
       " ['930', '0'],\n",
       " ['931', '1'],\n",
       " ['932', '0'],\n",
       " ['933', '1'],\n",
       " ['934', '0'],\n",
       " ['935', '1'],\n",
       " ['936', '1'],\n",
       " ['937', '0'],\n",
       " ['938', '0'],\n",
       " ['939', '0'],\n",
       " ['940', '1'],\n",
       " ['941', '1'],\n",
       " ['942', '1'],\n",
       " ['943', '0'],\n",
       " ['944', '0'],\n",
       " ['945', '1'],\n",
       " ['946', '1'],\n",
       " ['947', '0'],\n",
       " ['948', '0'],\n",
       " ['949', '0'],\n",
       " ['950', '0'],\n",
       " ['951', '1'],\n",
       " ['952', '0'],\n",
       " ['953', '0'],\n",
       " ['954', '0'],\n",
       " ['955', '1'],\n",
       " ['956', '0'],\n",
       " ['957', '0'],\n",
       " ['958', '1'],\n",
       " ['959', '0'],\n",
       " ['960', '0'],\n",
       " ['961', '1'],\n",
       " ['962', '1'],\n",
       " ['963', '0'],\n",
       " ['964', '1'],\n",
       " ['965', '0'],\n",
       " ['966', '1'],\n",
       " ['967', '1'],\n",
       " ['968', '1'],\n",
       " ['969', '0'],\n",
       " ['970', '0'],\n",
       " ['971', '1'],\n",
       " ['972', '0'],\n",
       " ['973', '0'],\n",
       " ['974', '0'],\n",
       " ['975', '0'],\n",
       " ['976', '1'],\n",
       " ['977', '0'],\n",
       " ['978', '1'],\n",
       " ['979', '1'],\n",
       " ['980', '0'],\n",
       " ['981', '0'],\n",
       " ['982', '1'],\n",
       " ['983', '0'],\n",
       " ['984', '1'],\n",
       " ['985', '0'],\n",
       " ['986', '0'],\n",
       " ['987', '0'],\n",
       " ['988', '1'],\n",
       " ['989', '0'],\n",
       " ['990', '1'],\n",
       " ['991', '0'],\n",
       " ['992', '1'],\n",
       " ['993', '0'],\n",
       " ['994', '0'],\n",
       " ['995', '0'],\n",
       " ['996', '0'],\n",
       " ['997', '0'],\n",
       " ['998', '0'],\n",
       " ['999', '1'],\n",
       " ['1000', '1'],\n",
       " ['1001', '0'],\n",
       " ['1002', '0'],\n",
       " ['1003', '1'],\n",
       " ['1004', '1'],\n",
       " ['1005', '1'],\n",
       " ['1006', '1'],\n",
       " ['1007', '0'],\n",
       " ['1008', '1'],\n",
       " ['1009', '1'],\n",
       " ['1010', '1'],\n",
       " ['1011', '1'],\n",
       " ['1012', '1'],\n",
       " ['1013', '1'],\n",
       " ['1014', '1'],\n",
       " ['1015', '0'],\n",
       " ['1016', '0'],\n",
       " ['1017', '1'],\n",
       " ['1018', '0'],\n",
       " ['1019', '0'],\n",
       " ['1020', '0'],\n",
       " ['1021', '0'],\n",
       " ['1022', '0'],\n",
       " ['1023', '0'],\n",
       " ['1024', '1'],\n",
       " ['1025', '0'],\n",
       " ['1026', '0'],\n",
       " ['1027', '0'],\n",
       " ['1028', '0'],\n",
       " ['1029', '0'],\n",
       " ['1030', '1'],\n",
       " ['1031', '0'],\n",
       " ['1032', '0'],\n",
       " ['1033', '1'],\n",
       " ['1034', '0'],\n",
       " ['1035', '0'],\n",
       " ['1036', '0'],\n",
       " ['1037', '0'],\n",
       " ['1038', '1'],\n",
       " ['1039', '0'],\n",
       " ['1040', '1'],\n",
       " ['1041', '0'],\n",
       " ['1042', '1'],\n",
       " ['1043', '1'],\n",
       " ['1044', '1'],\n",
       " ['1045', '1'],\n",
       " ['1046', '0'],\n",
       " ['1047', '0'],\n",
       " ['1048', '1'],\n",
       " ['1049', '1'],\n",
       " ['1050', '0'],\n",
       " ['1051', '1'],\n",
       " ['1052', '1'],\n",
       " ['1053', '0'],\n",
       " ['1054', '1'],\n",
       " ['1055', '0'],\n",
       " ['1056', '0'],\n",
       " ['1057', '1'],\n",
       " ['1058', '1'],\n",
       " ['1059', '0'],\n",
       " ['1060', '0'],\n",
       " ['1061', '1'],\n",
       " ['1062', '1'],\n",
       " ['1063', '0'],\n",
       " ['1064', '0'],\n",
       " ['1065', '1'],\n",
       " ['1066', '0'],\n",
       " ['1067', '1'],\n",
       " ['1068', '1'],\n",
       " ['1069', '0'],\n",
       " ['1070', '1'],\n",
       " ['1071', '1'],\n",
       " ['1072', '0'],\n",
       " ['1073', '1'],\n",
       " ['1074', '1'],\n",
       " ['1075', '1'],\n",
       " ['1076', '1'],\n",
       " ['1077', '0'],\n",
       " ['1078', '1'],\n",
       " ['1079', '0'],\n",
       " ['1080', '1'],\n",
       " ['1081', '0'],\n",
       " ['1082', '0'],\n",
       " ['1083', '1'],\n",
       " ['1084', '0'],\n",
       " ['1085', '0'],\n",
       " ['1086', '1'],\n",
       " ['1087', '0'],\n",
       " ['1088', '1'],\n",
       " ['1089', '1'],\n",
       " ['1090', '0'],\n",
       " ['1091', '1'],\n",
       " ['1092', '0'],\n",
       " ['1093', '0'],\n",
       " ['1094', '0'],\n",
       " ['1095', '1'],\n",
       " ['1096', '0'],\n",
       " ['1097', '0'],\n",
       " ['1098', '1'],\n",
       " ['1099', '0'],\n",
       " ['1100', '1'],\n",
       " ['1101', '0'],\n",
       " ['1102', '0'],\n",
       " ['1103', '0'],\n",
       " ['1104', '1'],\n",
       " ['1105', '1'],\n",
       " ['1106', '0'],\n",
       " ['1107', '1'],\n",
       " ['1108', '1'],\n",
       " ['1109', '0'],\n",
       " ['1110', '1'],\n",
       " ['1111', '0'],\n",
       " ['1112', '1'],\n",
       " ['1113', '0'],\n",
       " ['1114', '1'],\n",
       " ['1115', '0'],\n",
       " ['1116', '1'],\n",
       " ['1117', '1'],\n",
       " ['1118', '0'],\n",
       " ['1119', '1'],\n",
       " ['1120', '0'],\n",
       " ['1121', '0'],\n",
       " ['1122', '1'],\n",
       " ['1123', '1'],\n",
       " ['1124', '0'],\n",
       " ['1125', '1'],\n",
       " ['1126', '1'],\n",
       " ['1127', '0'],\n",
       " ['1128', '0'],\n",
       " ['1129', '0'],\n",
       " ['1130', '0'],\n",
       " ['1131', '1'],\n",
       " ['1132', '1'],\n",
       " ['1133', '1'],\n",
       " ['1134', '0'],\n",
       " ['1135', '1'],\n",
       " ['1136', '1'],\n",
       " ['1137', '0'],\n",
       " ['1138', '1'],\n",
       " ['1139', '0'],\n",
       " ['1140', '1'],\n",
       " ['1141', '0'],\n",
       " ['1142', '0'],\n",
       " ['1143', '0'],\n",
       " ['1144', '0'],\n",
       " ['1145', '0'],\n",
       " ['1146', '1'],\n",
       " ['1147', '0'],\n",
       " ['1148', '0'],\n",
       " ['1149', '0'],\n",
       " ['1150', '1'],\n",
       " ['1151', '0'],\n",
       " ['1152', '1'],\n",
       " ['1153', '0'],\n",
       " ['1154', '1'],\n",
       " ['1155', '1'],\n",
       " ['1156', '0'],\n",
       " ['1157', '1'],\n",
       " ['1158', '0'],\n",
       " ['1159', '0'],\n",
       " ['1160', '1'],\n",
       " ['1161', '0'],\n",
       " ['1162', '1'],\n",
       " ['1163', '0'],\n",
       " ['1164', '1'],\n",
       " ['1165', '0'],\n",
       " ['1166', '0'],\n",
       " ['1167', '1'],\n",
       " ['1168', '0'],\n",
       " ['1169', '0'],\n",
       " ['1170', '0'],\n",
       " ['1171', '0'],\n",
       " ['1172', '1'],\n",
       " ['1173', '0'],\n",
       " ['1174', '0'],\n",
       " ['1175', '1'],\n",
       " ['1176', '1'],\n",
       " ['1177', '0'],\n",
       " ['1178', '1'],\n",
       " ['1179', '1'],\n",
       " ['1180', '0'],\n",
       " ['1181', '1'],\n",
       " ['1182', '1'],\n",
       " ['1183', '1'],\n",
       " ['1184', '0'],\n",
       " ['1185', '0'],\n",
       " ['1186', '0'],\n",
       " ['1187', '0'],\n",
       " ['1188', '1'],\n",
       " ['1189', '1'],\n",
       " ['1190', '1'],\n",
       " ['1191', '0'],\n",
       " ['1192', '0'],\n",
       " ['1193', '1'],\n",
       " ['1194', '0'],\n",
       " ['1195', '0'],\n",
       " ['1196', '0'],\n",
       " ['1197', '1'],\n",
       " ['1198', '0'],\n",
       " ['1199', '1'],\n",
       " ['1200', '0'],\n",
       " ['1201', '0'],\n",
       " ['1202', '0'],\n",
       " ['1203', '0'],\n",
       " ['1204', '1'],\n",
       " ['1205', '1'],\n",
       " ['1206', '1'],\n",
       " ['1207', '1'],\n",
       " ['1208', '0'],\n",
       " ['1209', '0'],\n",
       " ['1210', '0'],\n",
       " ['1211', '0'],\n",
       " ['1212', '0'],\n",
       " ['1213', '0'],\n",
       " ['1214', '0'],\n",
       " ['1215', '0'],\n",
       " ['1216', '1'],\n",
       " ['1217', '0'],\n",
       " ['1218', '1'],\n",
       " ['1219', '1'],\n",
       " ['1220', '0'],\n",
       " ['1221', '0'],\n",
       " ['1222', '1'],\n",
       " ['1223', '0'],\n",
       " ['1224', '1'],\n",
       " ['1225', '1'],\n",
       " ['1226', '0'],\n",
       " ['1227', '0'],\n",
       " ['1228', '0'],\n",
       " ['1229', '0'],\n",
       " ['1230', '0'],\n",
       " ['1231', '0'],\n",
       " ['1232', '0'],\n",
       " ['1233', '0'],\n",
       " ['1234', '0'],\n",
       " ['1235', '1'],\n",
       " ['1236', '0'],\n",
       " ['1237', '1'],\n",
       " ['1238', '0'],\n",
       " ['1239', '1'],\n",
       " ['1240', '0'],\n",
       " ['1241', '1'],\n",
       " ['1242', '1'],\n",
       " ['1243', '0'],\n",
       " ['1244', '1'],\n",
       " ['1245', '0'],\n",
       " ['1246', '1'],\n",
       " ['1247', '0'],\n",
       " ['1248', '1'],\n",
       " ['1249', '0'],\n",
       " ['1250', '1'],\n",
       " ['1251', '1'],\n",
       " ['1252', '0'],\n",
       " ['1253', '1'],\n",
       " ['1254', '1'],\n",
       " ['1255', '0'],\n",
       " ['1256', '1'],\n",
       " ['1257', '1'],\n",
       " ['1258', '1'],\n",
       " ['1259', '1'],\n",
       " ['1260', '1'],\n",
       " ['1261', '0'],\n",
       " ['1262', '0'],\n",
       " ['1263', '1'],\n",
       " ['1264', '0'],\n",
       " ['1265', '0'],\n",
       " ['1266', '1'],\n",
       " ['1267', '1'],\n",
       " ['1268', '0'],\n",
       " ['1269', '0'],\n",
       " ['1270', '0'],\n",
       " ['1271', '0'],\n",
       " ['1272', '0'],\n",
       " ['1273', '0'],\n",
       " ['1274', '1'],\n",
       " ['1275', '1'],\n",
       " ['1276', '0'],\n",
       " ['1277', '1'],\n",
       " ['1278', '0'],\n",
       " ['1279', '0'],\n",
       " ['1280', '0'],\n",
       " ['1281', '0'],\n",
       " ['1282', '1'],\n",
       " ['1283', '1'],\n",
       " ['1284', '1'],\n",
       " ['1285', '0'],\n",
       " ['1286', '0'],\n",
       " ['1287', '1'],\n",
       " ['1288', '0'],\n",
       " ['1289', '1'],\n",
       " ['1290', '0'],\n",
       " ['1291', '0'],\n",
       " ['1292', '1'],\n",
       " ['1293', '0'],\n",
       " ['1294', '1'],\n",
       " ['1295', '1'],\n",
       " ['1296', '0'],\n",
       " ['1297', '0'],\n",
       " ['1298', '0'],\n",
       " ['1299', '0'],\n",
       " ['1300', '1'],\n",
       " ['1301', '1'],\n",
       " ['1302', '0'],\n",
       " ['1303', '1'],\n",
       " ['1304', '1'],\n",
       " ['1305', '1'],\n",
       " ['1306', '1'],\n",
       " ['1307', '0'],\n",
       " ['1308', '0'],\n",
       " ['1309', '0']]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_submission_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e7a09d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
